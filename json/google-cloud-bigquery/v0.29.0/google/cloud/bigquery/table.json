{"id":"google/cloud/bigquery/table","name":"Table","title":["Google","Cloud","Bigquery","Table"],"description":"<h1 id=\"table\">Table</h1>\n\n<p>A named resource representing a BigQuery table that holds zero or more\nrecords. Every table is defined by a schema that may contain nested and\nrepeated fields.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L69","resources":[{"title":"Preparing Data for BigQuery","link":"https://cloud.google.com/bigquery/preparing-data-for-bigquery"}],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ntable = dataset.create_table \"my_table\" do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend\n\nrow = {\n  \"first_name\" => \"Alice\",\n  \"cities_lived\" => [\n    {\n      \"place\" => \"Seattle\",\n      \"number_of_years\" => 5\n    },\n    {\n      \"place\" => \"Stockholm\",\n      \"number_of_years\" => 6\n    }\n  ]\n}\ntable.insert row"}],"methods":[{"id":"table_id-instance","type":"instance","name":"table_id","title":["Google","Cloud","Bigquery","Table#table_id"],"description":"<p>A unique ID for this table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L93","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The ID must contain only letters (a-z, A-Z), numbers\n(0-9), or underscores (_). The maximum length is 1,024 characters."}]},{"id":"dataset_id-instance","type":"instance","name":"dataset_id","title":["Google","Cloud","Bigquery","Table#dataset_id"],"description":"<p>The ID of the <code>Dataset</code> containing this table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L105","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The ID must contain only letters (a-z, A-Z), numbers\n(0-9), or underscores (_). The maximum length is 1,024 characters."}]},{"id":"project_id-instance","type":"instance","name":"project_id","title":["Google","Cloud","Bigquery","Table#project_id"],"description":"<p>The ID of the <code>Project</code> containing this table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L116","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The project ID."}]},{"id":"time_partitioning?-instance","type":"instance","name":"time_partitioning?","title":["Google","Cloud","Bigquery","Table#time_partitioning?"],"description":"<p>Checks if the table is time-partitioned. See <a href=\"https://cloud.google.com/bigquery/docs/partitioned-tables\">Partitioned\nTables</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L138","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"<code>true</code> when the table is time-partitioned, <code>false</code>\notherwise."}]},{"id":"time_partitioning_type-instance","type":"instance","name":"time_partitioning_type","title":["Google","Cloud","Bigquery","Table#time_partitioning_type"],"description":"<p>The period for which the table is partitioned, if any. See\n<a href=\"https://cloud.google.com/bigquery/docs/partitioned-tables\">Partitioned Tables</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L151","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String","nil"],"description":"The partition type. Currently the only supported\nvalue is “DAY”."}]},{"id":"time_partitioning_type=-instance","type":"instance","name":"time_partitioning_type=","title":["Google","Cloud","Bigquery","Table#time_partitioning_type="],"description":"<p>Sets the partitioning for the table. See <a href=\"https://cloud.google.com/bigquery/docs/partitioned-tables\">Partitioned\nTables</a>.</p>\n\n<p>You can only set partitioning when creating a table as in\nthe example below. BigQuery does not allow you to change partitioning\non an existing table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L178","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.create_table \"my_table\" do |table|\n  table.time_partitioning_type = \"DAY\"\nend"}],"params":[{"name":"type","types":["String"],"description":"The partition type. Currently the only\nsupported value is “DAY”.","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"time_partitioning_expiration-instance","type":"instance","name":"time_partitioning_expiration","title":["Google","Cloud","Bigquery","Table#time_partitioning_expiration"],"description":"<p>The expiration for the table partitions, if any, in seconds. See\n<a href=\"https://cloud.google.com/bigquery/docs/partitioned-tables\">Partitioned Tables</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L195","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Integer","nil"],"description":"The expiration time, in seconds, for data in\npartitions."}]},{"id":"time_partitioning_expiration=-instance","type":"instance","name":"time_partitioning_expiration=","title":["Google","Cloud","Bigquery","Table#time_partitioning_expiration="],"description":"<p>Sets the partition expiration for the table. See <a href=\"https://cloud.google.com/bigquery/docs/partitioned-tables\">Partitioned\nTables</a>.\nThe table must also be partitioned.</p>\n\n<p>See <a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"time_partitioning_type=-instance\">Table#time_partitioning_type=</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L224","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.create_table \"my_table\" do |table|\n  table.time_partitioning_type = \"DAY\"\n  table.time_partitioning_expiration = 86_400\nend"}],"params":[{"name":"expiration","types":["Integer"],"description":"An expiration time, in seconds,\nfor data in partitions.","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"id-instance","type":"instance","name":"id","title":["Google","Cloud","Bigquery","Table#id"],"description":"<p>The combined Project ID, Dataset ID, and Table ID for this table, in\nthe format specified by the <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Legacy SQL Query\nReference</a>:\n<code>project_name:datasetId.tableId</code>. To use this value in queries see\n<a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"query_id-instance\">#query_id</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L242","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The combined ID."}]},{"id":"query_id-instance","type":"instance","name":"query_id","title":["Google","Cloud","Bigquery","Table#query_id"],"description":"<p>The value returned by <a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"id-instance\">#id</a>, wrapped in square brackets if the Project\nID contains dashes, as specified by the <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Query\nReference</a>.\nUseful in queries.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L275","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ndata = bigquery.query \"SELECT first_name FROM #{table.query_id}\""}],"params":[{"name":"standard_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\ndialect. Optional. The default value is true.","optional":true,"default":"nil","nullable":true},{"name":"legacy_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect. Optional. The default value is false.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["String"],"description":"The appropriate table ID for use in queries,\ndepending on SQL type."}]},{"id":"name-instance","type":"instance","name":"name","title":["Google","Cloud","Bigquery","Table#name"],"description":"<p>The name of the table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L290","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The friendly name."}]},{"id":"name=-instance","type":"instance","name":"name=","title":["Google","Cloud","Bigquery","Table#name="],"description":"<p>Updates the name of the table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L301","resources":[],"examples":[],"params":[{"name":"new_name","types":["String"],"description":"The new friendly name.","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"etag-instance","type":"instance","name":"etag","title":["Google","Cloud","Bigquery","Table#etag"],"description":"<p>The ETag hash of the table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L313","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The ETag hash."}]},{"id":"api_url-instance","type":"instance","name":"api_url","title":["Google","Cloud","Bigquery","Table#api_url"],"description":"<p>A URL that can be used to access the table using the REST API.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L325","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"A REST URL for the resource."}]},{"id":"description-instance","type":"instance","name":"description","title":["Google","Cloud","Bigquery","Table#description"],"description":"<p>A user-friendly description of the table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L337","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The description."}]},{"id":"description=-instance","type":"instance","name":"description=","title":["Google","Cloud","Bigquery","Table#description="],"description":"<p>Updates the user-friendly description of the table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L349","resources":[],"examples":[],"params":[{"name":"new_description","types":["String"],"description":"The new user-friendly description.","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"bytes_count-instance","type":"instance","name":"bytes_count","title":["Google","Cloud","Bigquery","Table#bytes_count"],"description":"<p>The number of bytes in the table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L361","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Integer"],"description":"The count of bytes in the table."}]},{"id":"rows_count-instance","type":"instance","name":"rows_count","title":["Google","Cloud","Bigquery","Table#rows_count"],"description":"<p>The number of rows in the table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L377","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Integer"],"description":"The count of rows in the table."}]},{"id":"created_at-instance","type":"instance","name":"created_at","title":["Google","Cloud","Bigquery","Table#created_at"],"description":"<p>The time when this table was created.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L393","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/time\">Time</a>","nil"],"description":"The creation time."}]},{"id":"expires_at-instance","type":"instance","name":"expires_at","title":["Google","Cloud","Bigquery","Table#expires_at"],"description":"<p>The time when this table expires.\nIf not present, the table will persist indefinitely.\nExpired tables will be deleted and their storage reclaimed.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L411","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/time\">Time</a>","nil"],"description":"The expiration time."}]},{"id":"modified_at-instance","type":"instance","name":"modified_at","title":["Google","Cloud","Bigquery","Table#modified_at"],"description":"<p>The date when this table was last modified.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L427","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/time\">Time</a>","nil"],"description":"The last modified time."}]},{"id":"table?-instance","type":"instance","name":"table?","title":["Google","Cloud","Bigquery","Table#table?"],"description":"<p>Checks if the table’s type is “TABLE”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L443","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"<code>true</code> when the type is <code>TABLE</code>, <code>false</code> otherwise."}]},{"id":"view?-instance","type":"instance","name":"view?","title":["Google","Cloud","Bigquery","Table#view?"],"description":"<p>Checks if the table’s type is “VIEW”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L454","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"<code>true</code> when the type is <code>VIEW</code>, <code>false</code> otherwise."}]},{"id":"external?-instance","type":"instance","name":"external?","title":["Google","Cloud","Bigquery","Table#external?"],"description":"<p>Checks if the table’s type is “EXTERNAL”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L466","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"<code>true</code> when the type is <code>EXTERNAL</code>, <code>false</code>\notherwise."}]},{"id":"location-instance","type":"instance","name":"location","title":["Google","Cloud","Bigquery","Table#location"],"description":"<p>The geographic location where the table should reside. Possible\nvalues include <code>EU</code> and <code>US</code>. The default value is <code>US</code>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L478","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The location code."}]},{"id":"labels-instance","type":"instance","name":"labels","title":["Google","Cloud","Bigquery","Table#labels"],"description":"<p>A hash of user-provided labels associated with this table. Labels\nare used to organize and group tables. See <a href=\"https://cloud.google.com/bigquery/docs/labels\">Using\nLabels</a>.</p>\n\n<p>The returned hash is frozen and changes are not allowed. Use\n<a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"labels=-instance\">#labels=</a> to replace the entire hash.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L505","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nlabels = table.labels\nlabels[\"department\"] #=> \"shipping\""}],"params":[],"exceptions":[],"returns":[{"types":["Hash&lt;String, String&gt;"],"description":"A hash containing key/value pairs."}]},{"id":"labels=-instance","type":"instance","name":"labels=","title":["Google","Cloud","Bigquery","Table#labels="],"description":"<p>Updates the hash of user-provided labels associated with this table.\nLabels are used to organize and group tables. See <a href=\"https://cloud.google.com/bigquery/docs/labels\">Using\nLabels</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L537","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ntable.labels = { \"department\" => \"shipping\" }"}],"params":[{"name":"labels","types":["Hash<String, String>"],"description":"A hash containing key/value\npairs.</p>\n\n<ul>\n  <li>Label keys and values can be no longer than 63 characters.</li>\n  <li>Label keys and values can contain only lowercase letters, numbers,\nunderscores, hyphens, and international characters.</li>\n  <li>Label keys and values cannot exceed 128 bytes in size.</li>\n  <li>Label keys must begin with a letter.</li>\n  <li>Label keys must be unique within a table.</li>\n</ul>","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"schema-instance","type":"instance","name":"schema","title":["Google","Cloud","Bigquery","Table#schema"],"description":"<p>Returns the table’s schema. This method can also be used to set,\nreplace, or add to the schema by passing a block. See <a data-custom-type=\"google/cloud/bigquery/schema\">Schema</a> for\navailable methods.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L574","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.create_table \"my_table\"\n\ntable.schema do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend"}],"params":[{"name":"replace","types":["Boolean"],"description":"Whether to replace the existing schema with\nthe new schema. If <code>true</code>, the fields will replace the existing\nschema. If <code>false</code>, the fields will be added to the existing schema.\nWhen a table already contains data, schema changes must be additive.\nThus, the default value is <code>false</code>.","optional":true,"default":"false","nullable":false},{"name":"yield","types":["block"],"description":"a block for setting the schema","optional":true,"nullable":false},{"name":"yield.schema","types":["Schema"],"description":"the object accepting the schema","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/schema\">Google::Cloud::Bigquery::Schema</a>"],"description":"A frozen schema object."}]},{"id":"fields-instance","type":"instance","name":"fields","title":["Google","Cloud","Bigquery","Table#fields"],"description":"<p>The fields of the table, obtained from its schema.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L606","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ntable.fields.each do |field|\n  puts field.name\nend"}],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/bigquery/schema/field\">Schema::Field</a>&gt;"],"description":"An array of field objects."}]},{"id":"headers-instance","type":"instance","name":"headers","title":["Google","Cloud","Bigquery","Table#headers"],"description":"<p>The names of the columns in the table, obtained from its schema.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L628","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ntable.headers.each do |header|\n  puts header\nend"}],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;Symbol&gt;"],"description":"An array of column names."}]},{"id":"external-instance","type":"instance","name":"external","title":["Google","Cloud","Bigquery","Table#external"],"description":"<p>The <a data-custom-type=\"google/cloud/bigquery/external/datasource\">External::DataSource</a> (or subclass) object that represents the\nexternal data source that the table represents. Data can be queried\nthe table, even though the data is not stored in BigQuery. Instead of\nloading or streaming the data, this object references the external\ndata source.</p>\n\n<p>Present only if the table represents an External Data Source. See\n<a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"external?-instance\">#external?</a> and <a data-custom-type=\"google/cloud/bigquery/external/datasource\">External::DataSource</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L649","resources":[{"title":"Querying External Data Sources","link":"https://cloud.google.com/bigquery/external-data-sources"}],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/external/datasource\">External::DataSource</a>"],"description":"The external data source.</p>\n\n<p>@!group Attributes"}]},{"id":"external=-instance","type":"instance","name":"external=","title":["Google","Cloud","Bigquery","Table#external="],"description":"<p>Set the <a data-custom-type=\"google/cloud/bigquery/external/datasource\">External::DataSource</a> (or subclass) object that represents\nthe external data source that the table represents. Data can be\nqueried the table, even though the data is not stored in BigQuery.\nInstead of loading or streaming the data, this object references the\nexternal data source.</p>\n\n<p>Use only if the table represents an External Data Source. See\n<a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"external?-instance\">#external?</a> and <a data-custom-type=\"google/cloud/bigquery/external/datasource\">External::DataSource</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L671","resources":[{"title":"Querying External Data Sources","link":"https://cloud.google.com/bigquery/external-data-sources"}],"examples":[],"params":[{"name":"external","types":["External::DataSource"],"description":"An external data source.","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"buffer_bytes-instance","type":"instance","name":"buffer_bytes","title":["Google","Cloud","Bigquery","Table#buffer_bytes"],"description":"<p>A lower-bound estimate of the number of bytes currently in this\ntable’s streaming buffer, if one is present. This field will be absent\nif the table is not being streamed to or if there is no data in the\nstreaming buffer.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L686","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Integer"],"description":"The estimated number of bytes in the buffer."}]},{"id":"buffer_rows-instance","type":"instance","name":"buffer_rows","title":["Google","Cloud","Bigquery","Table#buffer_rows"],"description":"<p>A lower-bound estimate of the number of rows currently in this\ntable’s streaming buffer, if one is present. This field will be absent\nif the table is not being streamed to or if there is no data in the\nstreaming buffer.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L701","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Integer"],"description":"The estimated number of rows in the buffer."}]},{"id":"buffer_oldest_at-instance","type":"instance","name":"buffer_oldest_at","title":["Google","Cloud","Bigquery","Table#buffer_oldest_at"],"description":"<p>The time of the oldest entry currently in this table’s streaming\nbuffer, if one is present. This field will be absent if the table is\nnot being streamed to or if there is no data in the streaming buffer.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L715","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/time\">Time</a>","nil"],"description":"The oldest entry time."}]},{"id":"data-instance","type":"instance","name":"data","title":["Google","Cloud","Bigquery","Table#data"],"description":"<p>Retrieves data from the table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L766","resources":[],"examples":[{"caption":"<p>Paginate rows of data: (See <a data-custom-type=\"google/cloud/bigquery/data\" data-method=\"next-instance\">Data#next</a>)</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ndata = table.data\ndata.each do |row|\n  puts row[:first_name]\nend\nif data.next?\n  more_data = data.next if data.next?\nend"},{"caption":"<p>Retrieve all rows of data: (See <a data-custom-type=\"google/cloud/bigquery/data\" data-method=\"all-instance\">Data#all</a>)</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ndata = table.data\ndata.all do |row|\n  puts row[:first_name]\nend"}],"params":[{"name":"token","types":["String"],"description":"Page token, returned by a previous call,\nidentifying the result set.","optional":true,"default":"nil","nullable":true},{"name":"max","types":["Integer"],"description":"Maximum number of results to return.","optional":true,"default":"nil","nullable":true},{"name":"start","types":["Integer"],"description":"Zero-based index of the starting row to read.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/data\">Google::Cloud::Bigquery::Data</a>"],"description":""}]},{"id":"copy_job-instance","type":"instance","name":"copy_job","title":["Google","Cloud","Bigquery","Table#copy_job"],"description":"<p>Copies the data from the table to another table using an asynchronous\nmethod. In this method, a <a data-custom-type=\"google/cloud/bigquery/copyjob\">CopyJob</a> is immediately returned. The\ncaller may poll the service by repeatedly calling <a data-custom-type=\"google/cloud/bigquery/job\" data-method=\"reload!-instance\">Job#reload!</a> and\n<a data-custom-type=\"google/cloud/bigquery/job\" data-method=\"done?-instance\">Job#done?</a> to detect when the job is done, or simply block until the\njob is done by calling #<a data-custom-type=\"google/cloud/bigquery/job\" data-method=\"wait_until_done!-instance\">Job#wait_until_done!</a>. See also <a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"copy-instance\">#copy</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L849","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\ndestination_table = dataset.table \"my_destination_table\"\n\ncopy_job = table.copy_job destination_table"},{"caption":"<p>Passing a string identifier for the destination table:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ncopy_job = table.copy_job \"other-project:other_dataset.other_table\""}],"params":[{"name":"destination_table","types":["Table","String"],"description":"The destination for the\ncopied data. This can also be a string identifier as specified by\nthe <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Query\nReference</a>:\n<code>project_name:datasetId.tableId</code>. This is useful for referencing\ntables in other projects and datasets.","optional":false,"nullable":false},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables. The default value is <code>needed</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in\nthe destination table. The default value is <code>empty</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - An error will be returned if the destination table\nalready contains data.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"job_id","types":["String"],"description":"A user-defined ID for the copy job. The ID\nmust contain only letters (a-z, A-Z), numbers (0-9), underscores\n(_), or dashes (-). The maximum length is 1,024 characters. If\n<code>job_id</code> is provided, then <code>prefix</code> will not be used.</p>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/managing-jobs#generate-jobid\">Generating a job\nID</a>.","optional":true,"default":"nil","nullable":true},{"name":"prefix","types":["String"],"description":"A string, usually human-readable, that will be\nprepended to a generated value to produce a unique job ID. For\nexample, the prefix <code>daily_import_job_</code> can be given to generate a\njob ID such as <code>daily_import_job_12vEDtMQ0mbp1Mo5Z7mzAFQJZazh</code>. The\nprefix must contain only letters (a-z, A-Z), numbers (0-9),\nunderscores (_), or dashes (-). The maximum length of the entire ID\nis 1,024 characters. If <code>job_id</code> is provided, then <code>prefix</code> will not\nbe used.","optional":true,"default":"nil","nullable":true},{"name":"labels","types":["Hash"],"description":"A hash of user-provided labels associated with\nthe job. You can use these to organize and group your jobs. Label\nkeys and values can be no longer than 63 characters, can only\ncontain lowercase letters, numeric characters, underscores and\ndashes. International characters are allowed. Label values are\noptional. Label keys must start with a letter and each label in the\nlist must have a different key.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/copyjob\">Google::Cloud::Bigquery::CopyJob</a>"],"description":""}]},{"id":"copy-instance","type":"instance","name":"copy","title":["Google","Cloud","Bigquery","Table#copy"],"description":"<p>Copies the data from the table to another table using a synchronous\nmethod that blocks for a response. Timeouts and transient errors are\ngenerally handled as needed to complete the job. See also\n<a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"copy_job-instance\">#copy_job</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L913","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\ndestination_table = dataset.table \"my_destination_table\"\n\ntable.copy destination_table"},{"caption":"<p>Passing a string identifier for the destination table:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ntable.copy \"other-project:other_dataset.other_table\""}],"params":[{"name":"destination_table","types":["Table","String"],"description":"The destination for the\ncopied data. This can also be a string identifier as specified by\nthe <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Query\nReference</a>:\n<code>project_name:datasetId.tableId</code>. This is useful for referencing\ntables in other projects and datasets.","optional":false,"nullable":false},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables. The default value is <code>needed</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in\nthe destination table. The default value is <code>empty</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - An error will be returned if the destination table\nalready contains data.</li>\n</ul>","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Boolean"],"description":"Returns <code>true</code> if the copy operation succeeded."}]},{"id":"extract_job-instance","type":"instance","name":"extract_job","title":["Google","Cloud","Bigquery","Table#extract_job"],"description":"<p>Extracts the data from the table to a Google Cloud Storage file using\nan asynchronous method. In this method, an <a data-custom-type=\"google/cloud/bigquery/extractjob\">ExtractJob</a> is immediately\nreturned. The caller may poll the service by repeatedly calling\n<a data-custom-type=\"google/cloud/bigquery/job\" data-method=\"reload!-instance\">Job#reload!</a> and <a data-custom-type=\"google/cloud/bigquery/job\" data-method=\"done?-instance\">Job#done?</a> to detect when the job is done, or\nsimply block until the job is done by calling #<a data-custom-type=\"google/cloud/bigquery/job\" data-method=\"wait_until_done!-instance\">Job#wait_until_done!</a>.\nSee also <a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"extract-instance\">#extract</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L997","resources":[{"title":"Exporting Data From BigQuery","link":"https://cloud.google.com/bigquery/exporting-data-from-bigquery"}],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nextract_job = table.extract_job \"gs://my-bucket/file-name.json\",\n                            format: \"json\""}],"params":[{"name":"extract_url","types":["Google::Cloud::Storage::File","String","Array<String>"],"description":"The Google Storage file or file URI pattern(s) to which\nBigQuery should extract the table data.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is\n<code>csv</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"compression","types":["String"],"description":"The compression type to use for exported\nfiles. Possible values include <code>GZIP</code> and <code>NONE</code>. The default value\nis <code>NONE</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Delimiter to use between fields in the\nexported data. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"header","types":["Boolean"],"description":"Whether to print out a header row in the\nresults. Default is <code>true</code>.","optional":true,"default":"nil","nullable":true},{"name":"job_id","types":["String"],"description":"A user-defined ID for the extract job. The ID\nmust contain only letters (a-z, A-Z), numbers (0-9), underscores\n(_), or dashes (-). The maximum length is 1,024 characters. If\n<code>job_id</code> is provided, then <code>prefix</code> will not be used.</p>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/managing-jobs#generate-jobid\">Generating a job\nID</a>.","optional":true,"default":"nil","nullable":true},{"name":"prefix","types":["String"],"description":"A string, usually human-readable, that will be\nprepended to a generated value to produce a unique job ID. For\nexample, the prefix <code>daily_import_job_</code> can be given to generate a\njob ID such as <code>daily_import_job_12vEDtMQ0mbp1Mo5Z7mzAFQJZazh</code>. The\nprefix must contain only letters (a-z, A-Z), numbers (0-9),\nunderscores (_), or dashes (-). The maximum length of the entire ID\nis 1,024 characters. If <code>job_id</code> is provided, then <code>prefix</code> will not\nbe used.","optional":true,"default":"nil","nullable":true},{"name":"labels","types":["Hash"],"description":"A hash of user-provided labels associated with\nthe job. You can use these to organize and group your jobs. Label\nkeys and values can be no longer than 63 characters, can only\ncontain lowercase letters, numeric characters, underscores and\ndashes. International characters are allowed. Label values are\noptional. Label keys must start with a letter and each label in the\nlist must have a different key.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/extractjob\">Google::Cloud::Bigquery::ExtractJob</a>"],"description":""}]},{"id":"extract-instance","type":"instance","name":"extract","title":["Google","Cloud","Bigquery","Table#extract"],"description":"<p>Extracts the data from the table to a Google Cloud Storage file using\na synchronous method that blocks for a response. Timeouts and\ntransient errors are generally handled as needed to complete the job.\nSee also <a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"extract_job-instance\">#extract_job</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L1050","resources":[{"title":"Exporting Data From BigQuery","link":"https://cloud.google.com/bigquery/exporting-data-from-bigquery"}],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ntable.extract \"gs://my-bucket/file-name.json\", format: \"json\""}],"params":[{"name":"extract_url","types":["Google::Cloud::Storage::File","String","Array<String>"],"description":"The Google Storage file or file URI pattern(s) to which\nBigQuery should extract the table data.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is\n<code>csv</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"compression","types":["String"],"description":"The compression type to use for exported\nfiles. Possible values include <code>GZIP</code> and <code>NONE</code>. The default value\nis <code>NONE</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Delimiter to use between fields in the\nexported data. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"header","types":["Boolean"],"description":"Whether to print out a header row in the\nresults. Default is <code>true</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Boolean"],"description":"Returns <code>true</code> if the extract operation succeeded."}]},{"id":"load_job-instance","type":"instance","name":"load_job","title":["Google","Cloud","Bigquery","Table#load_job"],"description":"<p>Loads data into the table. You can pass a google-cloud storage file\npath or a google-cloud storage file instance. Or, you can upload a\nfile directly. See <a href=\"https://cloud.google.com/bigquery/loading-data-post-request#multipart\">Loading Data with a POST Request</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L1225","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nload_job = table.load_job \"gs://my-bucket/file-name.csv\""},{"caption":"<p>Pass a google-cloud-storage <code>File</code> instance:</p>","code":"require \"google/cloud/bigquery\"\nrequire \"google/cloud/storage\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nstorage = Google::Cloud::Storage.new\nbucket = storage.bucket \"my-bucket\"\nfile = bucket.file \"file-name.csv\"\nload_job = table.load_job file"},{"caption":"<p>Upload a file directly:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nfile = File.open \"my_data.csv\"\nload_job = table.load_job file"}],"params":[{"name":"file","types":["File","Google::Cloud::Storage::File","String"],"description":"A file or the\nURI of a Google Cloud Storage file containing data to load into the\ntable.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is\n<code>csv</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n  <li><code>datastore_backup</code> - Cloud Datastore backup</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables. The default value is <code>needed</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in\nthe table. The default value is <code>append</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - An error will be returned if the table already contains\ndata.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"projection_fields","types":["Array<String>"],"description":"If the <code>format</code> option is set\nto <code>datastore_backup</code>, indicates which entity properties to load\nfrom a Cloud Datastore backup. Property names are case sensitive and\nmust be top-level properties. If not set, BigQuery loads all\nproperties. If any named property isn’t found in the Cloud Datastore\nbackup, an invalid error is returned.","optional":true,"default":"nil","nullable":true},{"name":"jagged_rows","types":["Boolean"],"description":"Accept rows that are missing trailing\noptional columns. The missing values are treated as nulls. If\n<code>false</code>, records with missing trailing columns are treated as bad\nrecords, and if there are too many bad records, an invalid error is\nreturned in the job result. The default value is <code>false</code>. Only\napplicable to CSV, ignored for other formats.","optional":true,"default":"nil","nullable":true},{"name":"quoted_newlines","types":["Boolean"],"description":"Indicates if BigQuery should allow\nquoted data sections that contain newline characters in a CSV file.\nThe default value is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"autodetect","types":["Boolean"],"description":"Indicates if BigQuery should\nautomatically infer the options and schema for CSV and JSON sources.\nThe default value is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"encoding","types":["String"],"description":"The character encoding of the data. The\nsupported values are <code>UTF-8</code> or <code>ISO-8859-1</code>. The default value is\n<code>UTF-8</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Specifices the separator for fields in a CSV\nfile. BigQuery converts the string to <code>ISO-8859-1</code> encoding, and\nthen uses the first byte of the encoded string to split the data in\nits raw, binary state. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Indicates if BigQuery should allow\nextra values that are not represented in the table schema. If true,\nthe extra values are ignored. If false, records with extra columns\nare treated as bad records, and if there are too many bad records,\nan invalid error is returned in the job result. The default value is\n<code>false</code>.</p>\n\n<p>The <code>format</code> property determines what BigQuery treats as an extra\nvalue:</p>\n\n<ul>\n  <li><code>CSV</code>: Trailing columns</li>\n  <li><code>JSON</code>: Named values that don’t match any column names</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"max_bad_records","types":["Integer"],"description":"The maximum number of bad records\nthat BigQuery can ignore when running the job. If the number of bad\nrecords exceeds this value, an invalid error is returned in the job\nresult. The default value is <code>0</code>, which requires that all records\nare valid.","optional":true,"default":"nil","nullable":true},{"name":"null_marker","types":["String"],"description":"Specifies a string that represents a null\nvalue in a CSV file. For example, if you specify <code>\\N</code>, BigQuery\ninterprets <code>\\N</code> as a null value when loading a CSV file. The default\nvalue is the empty string. If you set this property to a custom\nvalue, BigQuery throws an error if an empty string is present for\nall data types except for STRING and BYTE. For STRING and BYTE\ncolumns, BigQuery interprets the empty string as an empty value.","optional":true,"default":"nil","nullable":true},{"name":"quote","types":["String"],"description":"The value that is used to quote data sections in\na CSV file. BigQuery converts the string to ISO-8859-1 encoding, and\nthen uses the first byte of the encoded string to split the data in\nits raw, binary state. The default value is a double-quote\n<code>\"</code>. If your data does not contain quoted sections, set\nthe property value to an empty string. If your data contains quoted\nnewline characters, you must also set the allowQuotedNewlines\nproperty to true.","optional":true,"default":"nil","nullable":true},{"name":"skip_leading","types":["Integer"],"description":"The number of rows at the top of a CSV\nfile that BigQuery will skip when loading the data. The default\nvalue is <code>0</code>. This property is useful if you have header rows in the\nfile that should be skipped.","optional":true,"default":"nil","nullable":true},{"name":"job_id","types":["String"],"description":"A user-defined ID for the load job. The ID\nmust contain only letters (a-z, A-Z), numbers (0-9), underscores\n(_), or dashes (-). The maximum length is 1,024 characters. If\n<code>job_id</code> is provided, then <code>prefix</code> will not be used.</p>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/managing-jobs#generate-jobid\">Generating a job\nID</a>.","optional":true,"default":"nil","nullable":true},{"name":"prefix","types":["String"],"description":"A string, usually human-readable, that will be\nprepended to a generated value to produce a unique job ID. For\nexample, the prefix <code>daily_import_job_</code> can be given to generate a\njob ID such as <code>daily_import_job_12vEDtMQ0mbp1Mo5Z7mzAFQJZazh</code>. The\nprefix must contain only letters (a-z, A-Z), numbers (0-9),\nunderscores (_), or dashes (-). The maximum length of the entire ID\nis 1,024 characters. If <code>job_id</code> is provided, then <code>prefix</code> will not\nbe used.","optional":true,"default":"nil","nullable":true},{"name":"labels","types":["Hash"],"description":"A hash of user-provided labels associated with\nthe job. You can use these to organize and group your jobs. Label\nkeys and values can be no longer than 63 characters, can only\ncontain lowercase letters, numeric characters, underscores and\ndashes. International characters are allowed. Label values are\noptional. Label keys must start with a letter and each label in the\nlist must have a different key.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/loadjob\">Google::Cloud::Bigquery::LoadJob</a>"],"description":""}]},{"id":"load-instance","type":"instance","name":"load","title":["Google","Cloud","Bigquery","Table#load"],"description":"<p>Loads data into the table. You can pass a google-cloud storage file\npath or a google-cloud storage file instance. Or, you can upload a\nfile directly. See <a href=\"https://cloud.google.com/bigquery/loading-data-post-request#multipart\">Loading Data with a POST Request</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L1379","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nload_job = table.load_job \"gs://my-bucket/file-name.csv\""},{"caption":"<p>Pass a google-cloud-storage <code>File</code> instance:</p>","code":"require \"google/cloud/bigquery\"\nrequire \"google/cloud/storage\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nstorage = Google::Cloud::Storage.new\nbucket = storage.bucket \"my-bucket\"\nfile = bucket.file \"file-name.csv\"\nload_job = table.load_job file"},{"caption":"<p>Upload a file directly:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nfile = File.open \"my_data.csv\"\nload_job = table.load_job file"}],"params":[{"name":"file","types":["File","Google::Cloud::Storage::File","String"],"description":"A file or the\nURI of a Google Cloud Storage file containing data to load into the\ntable.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is\n<code>csv</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n  <li><code>datastore_backup</code> - Cloud Datastore backup</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables. The default value is <code>needed</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in\nthe table. The default value is <code>append</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - An error will be returned if the table already contains\ndata.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"projection_fields","types":["Array<String>"],"description":"If the <code>format</code> option is set\nto <code>datastore_backup</code>, indicates which entity properties to load\nfrom a Cloud Datastore backup. Property names are case sensitive and\nmust be top-level properties. If not set, BigQuery loads all\nproperties. If any named property isn’t found in the Cloud Datastore\nbackup, an invalid error is returned.","optional":true,"default":"nil","nullable":true},{"name":"jagged_rows","types":["Boolean"],"description":"Accept rows that are missing trailing\noptional columns. The missing values are treated as nulls. If\n<code>false</code>, records with missing trailing columns are treated as bad\nrecords, and if there are too many bad records, an invalid error is\nreturned in the job result. The default value is <code>false</code>. Only\napplicable to CSV, ignored for other formats.","optional":true,"default":"nil","nullable":true},{"name":"quoted_newlines","types":["Boolean"],"description":"Indicates if BigQuery should allow\nquoted data sections that contain newline characters in a CSV file.\nThe default value is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"autodetect","types":["Boolean"],"description":"Indicates if BigQuery should\nautomatically infer the options and schema for CSV and JSON sources.\nThe default value is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"encoding","types":["String"],"description":"The character encoding of the data. The\nsupported values are <code>UTF-8</code> or <code>ISO-8859-1</code>. The default value is\n<code>UTF-8</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Specifices the separator for fields in a CSV\nfile. BigQuery converts the string to <code>ISO-8859-1</code> encoding, and\nthen uses the first byte of the encoded string to split the data in\nits raw, binary state. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Indicates if BigQuery should allow\nextra values that are not represented in the table schema. If true,\nthe extra values are ignored. If false, records with extra columns\nare treated as bad records, and if there are too many bad records,\nan invalid error is returned in the job result. The default value is\n<code>false</code>.</p>\n\n<p>The <code>format</code> property determines what BigQuery treats as an extra\nvalue:</p>\n\n<ul>\n  <li><code>CSV</code>: Trailing columns</li>\n  <li><code>JSON</code>: Named values that don’t match any column names</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"max_bad_records","types":["Integer"],"description":"The maximum number of bad records\nthat BigQuery can ignore when running the job. If the number of bad\nrecords exceeds this value, an invalid error is returned in the job\nresult. The default value is <code>0</code>, which requires that all records\nare valid.","optional":true,"default":"nil","nullable":true},{"name":"null_marker","types":["String"],"description":"Specifies a string that represents a null\nvalue in a CSV file. For example, if you specify <code>\\N</code>, BigQuery\ninterprets <code>\\N</code> as a null value when loading a CSV file. The default\nvalue is the empty string. If you set this property to a custom\nvalue, BigQuery throws an error if an empty string is present for\nall data types except for STRING and BYTE. For STRING and BYTE\ncolumns, BigQuery interprets the empty string as an empty value.","optional":true,"default":"nil","nullable":true},{"name":"quote","types":["String"],"description":"The value that is used to quote data sections in\na CSV file. BigQuery converts the string to ISO-8859-1 encoding, and\nthen uses the first byte of the encoded string to split the data in\nits raw, binary state. The default value is a double-quote\n<code>\"</code>. If your data does not contain quoted sections, set\nthe property value to an empty string. If your data contains quoted\nnewline characters, you must also set the allowQuotedNewlines\nproperty to true.","optional":true,"default":"nil","nullable":true},{"name":"skip_leading","types":["Integer"],"description":"The number of rows at the top of a CSV\nfile that BigQuery will skip when loading the data. The default\nvalue is <code>0</code>. This property is useful if you have header rows in the\nfile that should be skipped.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/loadjob\">Google::Cloud::Bigquery::LoadJob</a>"],"description":""}]},{"id":"insert-instance","type":"instance","name":"insert","title":["Google","Cloud","Bigquery","Table#insert"],"description":"<p>Inserts data into the table for near-immediate querying, without the\nneed to complete a load operation before the data can appear in query\nresults.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L1443","resources":[{"title":"Streaming Data Into BigQuery","link":"https://cloud.google.com/bigquery/streaming-data-into-bigquery"}],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nrows = [\n  { \"first_name\" => \"Alice\", \"age\" => 21 },\n  { \"first_name\" => \"Bob\", \"age\" => 22 }\n]\ntable.insert rows"}],"params":[{"name":"rows","types":["Hash","Array<Hash>"],"description":"A hash object or array of hash objects\ncontaining the data. Required.","optional":false,"nullable":false},{"name":"skip_invalid","types":["Boolean"],"description":"Insert all valid rows of a request, even\nif invalid rows exist. The default value is <code>false</code>, which causes\nthe entire request to fail if any invalid rows exist.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Accept rows that contain values that\ndo not match the schema. The unknown values are ignored. Default is\nfalse, which treats unknown values as errors.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/insertresponse\">Google::Cloud::Bigquery::InsertResponse</a>"],"description":""}]},{"id":"insert_async-instance","type":"instance","name":"insert_async","title":["Google","Cloud","Bigquery","Table#insert_async"],"description":"<p>Create an asynchonous inserter object used to insert rows in batches.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L1496","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\ninserter = table.insert_async do |response|\n  log_insert \"inserted #{response.insert_count} rows \" \\\n    \"with #{response.error_count} errors\"\nend\n\nrows = [\n  { \"first_name\" => \"Alice\", \"age\" => 21 },\n  { \"first_name\" => \"Bob\", \"age\" => 22 }\n]\ninserter.insert rows\n\ninserter.stop.wait!"}],"params":[{"name":"skip_invalid","types":["Boolean"],"description":"Insert all valid rows of a request, even\nif invalid rows exist. The default value is <code>false</code>, which causes\nthe entire request to fail if any invalid rows exist.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Accept rows that contain values that\ndo not match the schema. The unknown values are ignored. Default is\nfalse, which treats unknown values as errors.","optional":true,"default":"nil","nullable":true},{"name":"max_rows","types":["Integer"],"description":"The maximum number of rows to be collected\nbefore the batch is published. Default is 500.","optional":true,"default":"500","nullable":false},{"name":"yield","types":["block"],"description":"the callback for when a batch of rows is inserted","optional":true,"nullable":false},{"name":"yield.response","types":["InsertResponse"],"description":"the result of the asynchonous\ninsert","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/table/asyncinserter\">Table::AsyncInserter</a>"],"description":"Returns inserter object."}]},{"id":"delete-instance","type":"instance","name":"delete","title":["Google","Cloud","Bigquery","Table#delete"],"description":"<p>Permanently deletes the table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L1523","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ntable.delete"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"Returns <code>true</code> if the table was deleted."}]},{"id":"reload!-instance","type":"instance","name":"reload!","title":["Google","Cloud","Bigquery","Table#reload!"],"description":"<p>Reloads the table with current data from the BigQuery service.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/table.rb#L1534","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]}]}