{"id":"google/cloud/bigquery/project","name":"Project","title":["Google","Cloud","Bigquery","Project"],"description":"<h1 id=\"project\">Project</h1>\n\n<p>Projects are top-level containers in Google Cloud Platform. They store\ninformation about billing and authorized users, and they contain\nBigQuery data. Each project has a friendly name and a unique ID.</p>\n\n<p>Google::Cloud::Bigquery::Project is the main object for interacting with\nGoogle BigQuery. <a data-custom-type=\"google/cloud/bigquery/dataset\">Google::Cloud::Bigquery::Dataset</a> objects are created,\naccessed, and deleted by Google::Cloud::Bigquery::Project.</p>\n\n<p>See Google::Cloud#bigquery.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L54","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\""}],"methods":[{"id":"name-instance","type":"instance","name":"name","title":["Google","Cloud","Bigquery","Project#name"],"description":"<p>The descriptive name of the project.\nCan only be present if the project was retrieved with <a data-custom-type=\"google/cloud/bigquery/project\" data-method=\"projects-instance\">#projects</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L54","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String","nil"],"description":"the current value of name"}]},{"id":"numeric_id-instance","type":"instance","name":"numeric_id","title":["Google","Cloud","Bigquery","Project#numeric_id"],"description":"<p>The numeric ID of the project.\nCan only be present if the project was retrieved with <a data-custom-type=\"google/cloud/bigquery/project\" data-method=\"projects-instance\">#projects</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L54","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Integer","nil"],"description":"the current value of numeric_id"}]},{"id":"initialize-constructor","type":"constructor","name":"initialize","title":["Google","Cloud","Bigquery","Project#initialize"],"description":"<p>Creates a new Service instance.</p>\n\n<p>See Google::Cloud.bigquery</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L65","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/project\">Project</a>"],"description":"a new instance of Project"}]},{"id":"project_id-instance","type":"instance","name":"project_id","title":["Google","Cloud","Bigquery","Project#project_id"],"description":"<p>The BigQuery project connected to.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L82","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new(\n  project_id: \"my-project\",\n  credentials: \"/path/to/keyfile.json\"\n)\n\nbigquery.project_id #=> \"my-project\""}],"params":[],"exceptions":[],"returns":[]},{"id":"service_account_email-instance","type":"instance","name":"service_account_email","title":["Google","Cloud","Bigquery","Project#service_account_email"],"description":"<p>The email address of the service account for the project used to\nconnect to BigQuery. (See also <a data-custom-type=\"google/cloud/bigquery/project\" data-method=\"project_id-instance\">#project_id</a>.)</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L93","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The service account email address."}]},{"id":"query_job-instance","type":"instance","name":"query_job","title":["Google","Cloud","Bigquery","Project#query_job"],"description":"<p>Queries data by creating a <a href=\"https://cloud.google.com/bigquery/docs/query-overview#query_jobs\">query\njob</a>.</p>\n\n<p>When using standard SQL and passing arguments using <code>params</code>, Ruby\ntypes are mapped to BigQuery types as follows:</p>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th>BigQuery</th>\n      <th>Ruby</th>\n      <th>Notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><code>BOOL</code></td>\n      <td><code>true</code>/<code>false</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>INT64</code></td>\n      <td><code>Integer</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>FLOAT64</code></td>\n      <td><code>Float</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>STRING</code></td>\n      <td><code>STRING</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>DATETIME</code></td>\n      <td><code>DateTime</code></td>\n      <td><code>DATETIME</code> does not support time zone.</td>\n    </tr>\n    <tr>\n      <td><code>DATE</code></td>\n      <td><code>Date</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>TIMESTAMP</code></td>\n      <td><code>Time</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>TIME</code></td>\n      <td><code>Google::Cloud::BigQuery::Time</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>BYTES</code></td>\n      <td><code>File</code>, <code>IO</code>, <code>StringIO</code>, or similar</td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>ARRAY</code></td>\n      <td><code>Array</code></td>\n      <td>Nested arrays, <code>nil</code> values are not supported.</td>\n    </tr>\n    <tr>\n      <td><code>STRUCT</code></td>\n      <td><code>Hash</code></td>\n      <td>Hash keys may be strings or symbols.</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types\">Data Types</a>\nfor an overview of each BigQuery data type, including allowed values.</p>\n\n<p>The geographic location for the job (“US”, “EU”, etc.) can be set via\n<a data-custom-type=\"google/cloud/bigquery/queryjob/updater\" data-method=\"location=-instance\">QueryJob::Updater#location=</a> in a block passed to this method.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L328","resources":[],"examples":[{"caption":"<p>Query using standard SQL:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\njob = bigquery.query_job \"SELECT name FROM \" \\\n                         \"`my_project.my_dataset.my_table`\"\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"},{"caption":"<p>Query using legacy SQL:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\njob = bigquery.query_job \"SELECT name FROM \" \\\n                         \" [my_project:my_dataset.my_table]\",\n                         legacy_sql: true\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"},{"caption":"<p>Query using positional query parameters:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\njob = bigquery.query_job \"SELECT name FROM \" \\\n                         \"`my_dataset.my_table`\" \\\n                         \" WHERE id = ?\",\n                         params: [1]\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"},{"caption":"<p>Query using named query parameters:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\njob = bigquery.query_job \"SELECT name FROM \" \\\n                         \"`my_dataset.my_table`\" \\\n                         \" WHERE id = @id\",\n                         params: { id: 1 }\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"},{"caption":"<p>Query using external data source, set destination:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.autodetect = true\n  csv.skip_leading_rows = 1\nend\n\njob = bigquery.query_job \"SELECT * FROM my_ext_table\" do |query|\n  query.external = { my_ext_table: csv_table }\n  dataset = bigquery.dataset \"my_dataset\", skip_lookup: true\n  query.table = dataset.table \"my_table\", skip_lookup: true\nend\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"}],"params":[{"name":"query","types":["String"],"description":"A query string, following the BigQuery <a href=\"https://cloud.google.com/bigquery/query-reference\">query\nsyntax</a>, of the\nquery to execute. Example: “SELECT count(f1) FROM\n[myProjectId:myDatasetId.myTableId]”.","optional":false,"nullable":false},{"name":"params","types":["Array","Hash"],"description":"Standard SQL only. Used to pass query\narguments when the <code>query</code> string contains either positional (<code>?</code>)\nor named (<code>@myparam</code>) query parameters. If value passed is an array\n<code>[\"foo\"]</code>, the query must use positional query parameters. If value\npassed is a hash <code>{ myparam: \"foo\" }</code>, the query must use named\nquery parameters. When set, <code>legacy_sql</code> will automatically be set\nto false and <code>standard_sql</code> to true.","optional":true,"default":"nil","nullable":true},{"name":"external","types":["Hash<String|Symbol, External::DataSource>"],"description":"A Hash\nthat represents the mapping of the external tables to the table\nnames used in the SQL query. The hash keys are the table names, and\nthe hash values are the external table objects. See <a data-custom-type=\"google/cloud/bigquery/project\" data-method=\"query-instance\">Project#query</a>.","optional":true,"default":"nil","nullable":true},{"name":"priority","types":["String"],"description":"Specifies a priority for the query. Possible\nvalues include <code>INTERACTIVE</code> and <code>BATCH</code>. The default value is\n<code>INTERACTIVE</code>.","optional":true,"default":"\"INTERACTIVE\"","nullable":false},{"name":"cache","types":["Boolean"],"description":"Whether to look for the result in the query\ncache. The query cache is a best-effort cache that will be flushed\nwhenever tables in the query are modified. The default value is\ntrue. For more information, see <a href=\"https://developers.google.com/bigquery/querying-data\">query\ncaching</a>.","optional":true,"default":"true","nullable":false},{"name":"table","types":["Table"],"description":"The destination table where the query results\nshould be stored. If not present, a new table will be created to\nstore the results.","optional":true,"default":"nil","nullable":true},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables. The default value is <code>needed</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies the action that occurs if the\ndestination table already exists. The default value is <code>empty</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - A ‘duplicate’ error is returned in the job result if the\ntable exists and contains data.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"dataset","types":["Dataset","String"],"description":"The default dataset to use for\nunqualified table names in the query. Optional.","optional":true,"default":"nil","nullable":true},{"name":"project","types":["String"],"description":"Specifies the default projectId to assume for\nany unqualified table names in the query. Only used if <code>dataset</code>\noption is set.","optional":true,"default":"nil","nullable":true},{"name":"standard_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\ndialect for this query. If set to true, the query will use standard\nSQL rather than the <a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect. Optional. The default value is true.","optional":true,"default":"nil","nullable":true},{"name":"legacy_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect for this query. If set to false, the query will use\nBigQuery’s <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\ndialect. Optional. The default value is false.","optional":true,"default":"nil","nullable":true},{"name":"large_results","types":["Boolean"],"description":"This option is specific to Legacy SQL.\nIf <code>true</code>, allows the query to produce arbitrarily large result\ntables at a slight cost in performance. Requires <code>table</code> parameter\nto be set.","optional":true,"default":"nil","nullable":true},{"name":"flatten","types":["Boolean"],"description":"This option is specific to Legacy SQL.\nFlattens all nested and repeated fields in the query results. The\ndefault value is <code>true</code>. <code>large_results</code> parameter must be <code>true</code> if\nthis is set to <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"maximum_bytes_billed","types":["Integer"],"description":"Limits the bytes billed for this\njob. Queries that will have bytes billed beyond this limit will fail\n(without incurring a charge). Optional. If unspecified, this will be\nset to your project default.","optional":true,"default":"nil","nullable":true},{"name":"job_id","types":["String"],"description":"A user-defined ID for the query job. The ID\nmust contain only letters (a-z, A-Z), numbers (0-9), underscores\n(_), or dashes (-). The maximum length is 1,024 characters. If\n<code>job_id</code> is provided, then <code>prefix</code> will not be used.</p>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/managing-jobs#generate-jobid\">Generating a job\nID</a>.","optional":true,"default":"nil","nullable":true},{"name":"prefix","types":["String"],"description":"A string, usually human-readable, that will be\nprepended to a generated value to produce a unique job ID. For\nexample, the prefix <code>daily_import_job_</code> can be given to generate a\njob ID such as <code>daily_import_job_12vEDtMQ0mbp1Mo5Z7mzAFQJZazh</code>. The\nprefix must contain only letters (a-z, A-Z), numbers (0-9),\nunderscores (_), or dashes (-). The maximum length of the entire ID\nis 1,024 characters. If <code>job_id</code> is provided, then <code>prefix</code> will not\nbe used.</p>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/managing-jobs#generate-jobid\">Generating a job\nID</a>.","optional":true,"default":"nil","nullable":true},{"name":"labels","types":["Hash"],"description":"A hash of user-provided labels associated with\nthe job. You can use these to organize and group your jobs. Label\nkeys and values can be no longer than 63 characters, can only\ncontain lowercase letters, numeric characters, underscores and\ndashes. International characters are allowed. Label values are\noptional. Label keys must start with a letter and each label in the\nlist must have a different key.","optional":true,"default":"nil","nullable":true},{"name":"udfs","types":["Array<String>","String"],"description":"User-defined function resources\nused in the query. May be either a code resource to load from a\nGoogle Cloud Storage URI (<code>gs://bucket/path</code>), or an inline resource\nthat contains code for a user-defined function (UDF). Providing an\ninline code resource is equivalent to providing a URI for a file\ncontaining the same code. See <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/user-defined-functions\">User-Defined\nFunctions</a>.","optional":true,"default":"nil","nullable":true},{"name":"maximum_billing_tier","types":["Integer"],"description":"Deprecated: Change the billing\ntier to allow high-compute queries.","optional":true,"default":"nil","nullable":true},{"name":"yield","types":["block"],"description":"a job configuration object","optional":true,"nullable":false},{"name":"yield.job","types":["Google::Cloud::Bigquery::QueryJob::Updater"],"description":"a job\nconfiguration object for setting query options.","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/queryjob\">Google::Cloud::Bigquery::QueryJob</a>"],"description":""}]},{"id":"query-instance","type":"instance","name":"query","title":["Google","Cloud","Bigquery","Project#query"],"description":"<p>Queries data and waits for the results. In this method, a <a data-custom-type=\"google/cloud/bigquery/queryjob\">QueryJob</a>\nis created and its results are saved to a temporary table, then read\nfrom the table. Timeouts and transient errors are generally handled\nas needed to complete the query.</p>\n\n<p>When using standard SQL and passing arguments using <code>params</code>, Ruby\ntypes are mapped to BigQuery types as follows:</p>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th>BigQuery</th>\n      <th>Ruby</th>\n      <th>Notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><code>BOOL</code></td>\n      <td><code>true</code>/<code>false</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>INT64</code></td>\n      <td><code>Integer</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>FLOAT64</code></td>\n      <td><code>Float</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>STRING</code></td>\n      <td><code>STRING</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>DATETIME</code></td>\n      <td><code>DateTime</code></td>\n      <td><code>DATETIME</code> does not support time zone.</td>\n    </tr>\n    <tr>\n      <td><code>DATE</code></td>\n      <td><code>Date</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>TIMESTAMP</code></td>\n      <td><code>Time</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>TIME</code></td>\n      <td><code>Google::Cloud::BigQuery::Time</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>BYTES</code></td>\n      <td><code>File</code>, <code>IO</code>, <code>StringIO</code>, or similar</td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>ARRAY</code></td>\n      <td><code>Array</code></td>\n      <td>Nested arrays, <code>nil</code> values are not supported.</td>\n    </tr>\n    <tr>\n      <td><code>STRUCT</code></td>\n      <td><code>Hash</code></td>\n      <td>Hash keys may be strings or symbols.</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types\">Data Types</a>\nfor an overview of each BigQuery data type, including allowed values.</p>\n\n<p>The geographic location for the job (“US”, “EU”, etc.) can be set via\n<a data-custom-type=\"google/cloud/bigquery/queryjob/updater\" data-method=\"location=-instance\">QueryJob::Updater#location=</a> in a block passed to this method.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L527","resources":[{"title":"Querying Data","link":"https://cloud.google.com/bigquery/querying-data"}],"examples":[{"caption":"<p>Query using standard SQL:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nsql = \"SELECT name FROM `my_project.my_dataset.my_table`\"\ndata = bigquery.query sql\n\ndata.each do |row|\n  puts row[:name]\nend"},{"caption":"<p>Query using legacy SQL:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nsql = \"SELECT name FROM [my_project:my_dataset.my_table]\"\ndata = bigquery.query sql, legacy_sql: true\n\ndata.each do |row|\n  puts row[:name]\nend"},{"caption":"<p>Retrieve all rows: (See <a data-custom-type=\"google/cloud/bigquery/data\" data-method=\"all-instance\">Data#all</a>)</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndata = bigquery.query \"SELECT name FROM `my_dataset.my_table`\"\n\ndata.all do |row|\n  puts row[:name]\nend"},{"caption":"<p>Query using positional query parameters:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndata = bigquery.query \"SELECT name \" \\\n                      \"FROM `my_dataset.my_table`\" \\\n                      \"WHERE id = ?\",\n                      params: [1]\n\ndata.each do |row|\n  puts row[:name]\nend"},{"caption":"<p>Query using named query parameters:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndata = bigquery.query \"SELECT name \" \\\n                      \"FROM `my_dataset.my_table`\" \\\n                      \"WHERE id = @id\",\n                      params: { id: 1 }\n\ndata.each do |row|\n  puts row[:name]\nend"},{"caption":"<p>Query using external data source, set destination:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.autodetect = true\n  csv.skip_leading_rows = 1\nend\n\ndata = bigquery.query \"SELECT * FROM my_ext_table\" do |query|\n  query.external = { my_ext_table: csv_table }\n  dataset = bigquery.dataset \"my_dataset\", skip_lookup: true\n  query.table = dataset.table \"my_table\", skip_lookup: true\nend\n\ndata.each do |row|\n  puts row[:name]\nend"}],"params":[{"name":"query","types":["String"],"description":"A query string, following the BigQuery <a href=\"https://cloud.google.com/bigquery/query-reference\">query\nsyntax</a>, of the\nquery to execute. Example: “SELECT count(f1) FROM\n[myProjectId:myDatasetId.myTableId]”.","optional":false,"nullable":false},{"name":"params","types":["Array","Hash"],"description":"Standard SQL only. Used to pass query\narguments when the <code>query</code> string contains either positional (<code>?</code>)\nor named (<code>@myparam</code>) query parameters. If value passed is an array\n<code>[\"foo\"]</code>, the query must use positional query parameters. If value\npassed is a hash <code>{ myparam: \"foo\" }</code>, the query must use named\nquery parameters. When set, <code>legacy_sql</code> will automatically be set\nto false and <code>standard_sql</code> to true.","optional":true,"default":"nil","nullable":true},{"name":"external","types":["Hash<String|Symbol, External::DataSource>"],"description":"A Hash\nthat represents the mapping of the external tables to the table\nnames used in the SQL query. The hash keys are the table names, and\nthe hash values are the external table objects. See <a data-custom-type=\"google/cloud/bigquery/project\" data-method=\"query-instance\">Project#query</a>.","optional":true,"default":"nil","nullable":true},{"name":"max","types":["Integer"],"description":"The maximum number of rows of data to return per\npage of results. Setting this flag to a small value such as 1000 and\nthen paging through results might improve reliability when the query\nresult set is large. In addition to this limit, responses are also\nlimited to 10 MB. By default, there is no maximum row count, and\nonly the byte limit applies.","optional":true,"default":"nil","nullable":true},{"name":"cache","types":["Boolean"],"description":"Whether to look for the result in the query\ncache. The query cache is a best-effort cache that will be flushed\nwhenever tables in the query are modified. The default value is\ntrue. For more information, see <a href=\"https://developers.google.com/bigquery/querying-data\">query\ncaching</a>.","optional":true,"default":"true","nullable":false},{"name":"dataset","types":["String"],"description":"Specifies the default datasetId and projectId\nto assume for any unqualified table names in the query. If not set,\nall table names in the query string must be qualified in the format\n‘datasetId.tableId’.","optional":true,"default":"nil","nullable":true},{"name":"project","types":["String"],"description":"Specifies the default projectId to assume for\nany unqualified table names in the query. Only used if <code>dataset</code>\noption is set.","optional":true,"default":"nil","nullable":true},{"name":"standard_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\ndialect for this query. If set to true, the query will use standard\nSQL rather than the <a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect. When set to true, the values of <code>large_results</code> and\n<code>flatten</code> are ignored; the query will be run as if <code>large_results</code>\nis true and <code>flatten</code> is false. Optional. The default value is\ntrue.","optional":true,"default":"nil","nullable":true},{"name":"legacy_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect for this query. If set to false, the query will use\nBigQuery’s <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\nWhen set to false, the values of <code>large_results</code> and <code>flatten</code> are\nignored; the query will be run as if <code>large_results</code> is true and\n<code>flatten</code> is false. Optional. The default value is false.","optional":true,"default":"nil","nullable":true},{"name":"yield","types":["block"],"description":"a job configuration object","optional":true,"nullable":false},{"name":"yield.job","types":["Google::Cloud::Bigquery::QueryJob::Updater"],"description":"a job\nconfiguration object for setting additional options for the query.","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/data\">Google::Cloud::Bigquery::Data</a>"],"description":""}]},{"id":"external-instance","type":"instance","name":"external","title":["Google","Cloud","Bigquery","Project#external"],"description":"<p>Creates a new External::DataSource (or subclass) object that\nrepresents the external data source that can be queried from directly,\neven though the data is not stored in BigQuery. Instead of loading or\nstreaming the data, this object references the external data source.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L594","resources":[{"title":"Querying\nExternal Data Sources","link":"https://cloud.google.com/bigquery/external-data-sources"}],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.autodetect = true\n  csv.skip_leading_rows = 1\nend\n\ndata = bigquery.query \"SELECT * FROM my_ext_table\",\n                      external: { my_ext_table: csv_table }\n\ndata.each do |row|\n  puts row[:name]\nend"}],"params":[{"name":"url","types":["String","Array<String>"],"description":"The fully-qualified URL(s) that\npoint to your data in Google Cloud. An attempt will be made to\nderive the format from the URLs provided.","optional":false,"nullable":false},{"name":"format","types":["String|Symbol"],"description":"The data format. This value will be used\neven if the provided URLs are recognized as a different format.\nOptional.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n  <li><code>sheets</code> - Google Sheets</li>\n  <li><code>datastore_backup</code> - Cloud Datastore backup</li>\n  <li><code>bigtable</code> - Bigtable</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"yield","types":["block"],"description":"","optional":true,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/external/datasource\">External::DataSource</a>"],"description":"External data source."}]},{"id":"dataset-instance","type":"instance","name":"dataset","title":["Google","Cloud","Bigquery","Project#dataset"],"description":"<p>Retrieves an existing dataset by ID.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L627","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\"\nputs dataset.name"},{"caption":"<p>Avoid retrieving the dataset resource with <code>skip_lookup</code>:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\", skip_lookup: true"}],"params":[{"name":"dataset_id","types":["String"],"description":"The ID of a dataset.","optional":false,"nullable":false},{"name":"skip_lookup","types":["Boolean"],"description":"Optionally create just a local reference\nobject without verifying that the resource exists on the BigQuery\nservice. Calls made on this object will raise errors if the resource\ndoes not exist. Default is <code>false</code>. Optional.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/dataset\">Google::Cloud::Bigquery::Dataset</a>","nil"],"description":"Returns <code>nil</code> if the\ndataset does not exist."}]},{"id":"create_dataset-instance","type":"instance","name":"create_dataset","title":["Google","Cloud","Bigquery","Project#create_dataset"],"description":"<p>Creates a new dataset.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L684","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.create_dataset \"my_dataset\""},{"caption":"<p>A name and description can be provided:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.create_dataset \"my_dataset\",\n                                  name: \"My Dataset\",\n                                  description: \"This is my Dataset\""},{"caption":"<p>Or, configure access with a block: (See <a data-custom-type=\"google/cloud/bigquery/dataset/access\">Dataset::Access</a>)</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.create_dataset \"my_dataset\" do |dataset|\n  dataset.access.add_writer_user \"writers@example.com\"\nend"}],"params":[{"name":"dataset_id","types":["String"],"description":"A unique ID for this dataset, without the\nproject name. The ID must contain only letters (a-z, A-Z), numbers\n(0-9), or underscores (_). The maximum length is 1,024 characters.","optional":false,"nullable":false},{"name":"name","types":["String"],"description":"A descriptive name for the dataset.","optional":true,"default":"nil","nullable":true},{"name":"description","types":["String"],"description":"A user-friendly description of the\ndataset.","optional":true,"default":"nil","nullable":true},{"name":"expiration","types":["Integer"],"description":"The default lifetime of all tables in the\ndataset, in milliseconds. The minimum value is 3600000 milliseconds\n(one hour).","optional":true,"default":"nil","nullable":true},{"name":"location","types":["String"],"description":"The geographic location where the dataset\nshould reside. Possible values include <code>EU</code> and <code>US</code>. The default\nvalue is <code>US</code>.","optional":true,"default":"nil","nullable":true},{"name":"yield","types":["block"],"description":"a block for setting rules","optional":true,"nullable":false},{"name":"yield.access","types":["Google::Cloud::Bigquery::Dataset"],"description":"the object\naccepting rules","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/dataset\">Google::Cloud::Bigquery::Dataset</a>"],"description":""}]},{"id":"datasets-instance","type":"instance","name":"datasets","title":["Google","Cloud","Bigquery","Project#datasets"],"description":"<p>Retrieves the list of datasets belonging to the project.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L756","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndatasets = bigquery.datasets\ndatasets.each do |dataset|\n  puts dataset.name\nend"},{"caption":"<p>Retrieve hidden datasets with the <code>all</code> optional arg:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nall_datasets = bigquery.datasets all: true"},{"caption":"<p>Retrieve all datasets: (See <a data-custom-type=\"google/cloud/bigquery/dataset/list\" data-method=\"all-instance\">Dataset::List#all</a>)</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndatasets = bigquery.datasets\ndatasets.all do |dataset|\n  puts dataset.name\nend"}],"params":[{"name":"all","types":["Boolean"],"description":"Whether to list all datasets, including hidden\nones. The default is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"filter","types":["String"],"description":"An expression for filtering the results of the\nrequest by label. The syntax is <code>labels.&lt;name&gt;[:&lt;value&gt;]</code>.\nMultiple filters can be <code>AND</code>ed together by connecting with a space.\nExample: <code>labels.department:receiving labels.active</code>. See <a href=\"https://cloud.google.com/bigquery/docs/labeling-datasets#filtering_datasets_using_labels\">Filtering\ndatasets using labels</a>.","optional":true,"default":"nil","nullable":true},{"name":"token","types":["String"],"description":"A previously-returned page token representing\npart of the larger set of results to view.","optional":true,"default":"nil","nullable":true},{"name":"max","types":["Integer"],"description":"Maximum number of datasets to return.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/bigquery/dataset\">Google::Cloud::Bigquery::Dataset</a>&gt;"],"description":"(See\n<a data-custom-type=\"google/cloud/bigquery/dataset/list\">Google::Cloud::Bigquery::Dataset::List</a>)"}]},{"id":"job-instance","type":"instance","name":"job","title":["Google","Cloud","Bigquery","Project#job"],"description":"<p>Retrieves an existing job by ID.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L780","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\njob = bigquery.job \"my_job\""}],"params":[{"name":"job_id","types":["String"],"description":"The ID of a job.","optional":false,"nullable":false},{"name":"location","types":["String"],"description":"The geographic location where the job was\ncreated. Required except for US and EU.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/job\">Google::Cloud::Bigquery::Job</a>","nil"],"description":"Returns <code>nil</code> if the job\ndoes not exist."}]},{"id":"jobs-instance","type":"instance","name":"jobs","title":["Google","Cloud","Bigquery","Project#jobs"],"description":"<p>Retrieves the list of jobs belonging to the project.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L837","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\njobs = bigquery.jobs\njobs.each do |job|\n  # process job\nend"},{"caption":"<p>Retrieve only running jobs using the <code>filter</code> optional arg:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nrunning_jobs = bigquery.jobs filter: \"running\"\nrunning_jobs.each do |job|\n  # process job\nend"},{"caption":"<p>Retrieve all jobs: (See <a data-custom-type=\"google/cloud/bigquery/job/list\" data-method=\"all-instance\">Job::List#all</a>)</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\njobs = bigquery.jobs\njobs.all do |job|\n  # process job\nend"}],"params":[{"name":"all","types":["Boolean"],"description":"Whether to display jobs owned by all users in the\nproject. The default is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"token","types":["String"],"description":"A previously-returned page token representing\npart of the larger set of results to view.","optional":true,"default":"nil","nullable":true},{"name":"max","types":["Integer"],"description":"Maximum number of jobs to return.","optional":true,"default":"nil","nullable":true},{"name":"filter","types":["String"],"description":"A filter for job state.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>done</code> - Finished jobs</li>\n  <li><code>pending</code> - Pending jobs</li>\n  <li><code>running</code> - Running jobs</li>\n</ul>","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/bigquery/job\">Google::Cloud::Bigquery::Job</a>&gt;"],"description":"(See\n<a data-custom-type=\"google/cloud/bigquery/job/list\">Google::Cloud::Bigquery::Job::List</a>)"}]},{"id":"projects-instance","type":"instance","name":"projects","title":["Google","Cloud","Bigquery","Project#projects"],"description":"<p>Retrieves the list of all projects for which the currently authorized\naccount has been granted any project role. The returned project\ninstances share the same credentials as the project used to retrieve\nthem, but lazily create a new API connection for interactions with the\nBigQuery service.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L885","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nprojects = bigquery.projects\nprojects.each do |project|\n  puts project.name\n  project.datasets.all.each do |dataset|\n    puts dataset.name\n  end\nend"},{"caption":"<p>Retrieve all projects: (See <a data-custom-type=\"google/cloud/bigquery/project/list\" data-method=\"all-instance\">Project::List#all</a>)</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nprojects = bigquery.projects\n\nprojects.all do |project|\n  puts project.name\n  project.datasets.all.each do |dataset|\n    puts dataset.name\n  end\nend"}],"params":[{"name":"token","types":["String"],"description":"A previously-returned page token representing\npart of the larger set of results to view.","optional":true,"default":"nil","nullable":true},{"name":"max","types":["Integer"],"description":"Maximum number of projects to return.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/bigquery/project\">Google::Cloud::Bigquery::Project</a>&gt;"],"description":"(See\n<a data-custom-type=\"google/cloud/bigquery/project/list\">Google::Cloud::Bigquery::Project::List</a>)"}]},{"id":"time-instance","type":"instance","name":"time","title":["Google","Cloud","Bigquery","Project#time"],"description":"<p>Creates a Bigquery::Time object to represent a time, independent of a\nspecific date.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L933","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nfourpm = bigquery.time 16, 0, 0\ndata = bigquery.query \"SELECT name \" \\\n                      \"FROM `my_dataset.my_table`\" \\\n                      \"WHERE time_of_date = @time\",\n                      params: { time: fourpm }\n\ndata.each do |row|\n  puts row[:name]\nend"},{"caption":"<p>Create Time with fractional seconds:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nprecise_time = bigquery.time 16, 35, 15.376541\ndata = bigquery.query \"SELECT name \" \\\n                      \"FROM `my_dataset.my_table`\" \\\n                      \"WHERE time_of_date >= @time\",\n                      params: { time: precise_time }\n\ndata.each do |row|\n  puts row[:name]\nend"}],"params":[{"name":"hour","types":["Integer"],"description":"Hour, valid values from 0 to 23.","optional":false,"nullable":false},{"name":"minute","types":["Integer"],"description":"Minute, valid values from 0 to 59.","optional":false,"nullable":false},{"name":"second","types":["Integer","Float"],"description":"Second, valid values from 0 to 59. Can\ncontain microsecond precision.","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/time\">Bigquery::Time</a>"],"description":""}]},{"id":"schema-instance","type":"instance","name":"schema","title":["Google","Cloud","Bigquery","Project#schema"],"description":"<p>Creates a new schema instance. An optional block may be given to\nconfigure the schema, otherwise the schema is returned empty and may\nbe configured directly.</p>\n\n<p>The returned schema can be passed to <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"load-instance\">Dataset#load</a> using the\n<code>schema</code> option. However, for most use cases, the block yielded by\n<a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"load-instance\">Dataset#load</a> is a more convenient way to configure the schema\nfor the destination table.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L970","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nschema = bigquery.schema do |s|\n  s.string \"first_name\", mode: :required\n  s.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend\n\ndataset = bigquery.dataset \"my_dataset\"\n\ngs_url = \"gs://my-bucket/file-name.csv\"\nload_job = dataset.load_job \"my_new_table\", gs_url, schema: schema"}],"params":[{"name":"yield","types":["block"],"description":"a block for setting the schema","optional":true,"nullable":false},{"name":"yield.schema","types":["Schema"],"description":"the object accepting the schema","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/schema\">Google::Cloud::Bigquery::Schema</a>"],"description":""}]},{"id":"encryption-instance","type":"instance","name":"encryption","title":["Google","Cloud","Bigquery","Project#encryption"],"description":"<p>Creates a new Bigquery::EncryptionConfiguration instance.</p>\n\n<p>This method does not execute an API call. Use the encryption\nconfiguration to encrypt a table when creating one via\nBigquery::Dataset#create_table, Bigquery::Dataset#load,\nBigquery::Table#copy, or Bigquery::Project#query.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/project.rb#L1041","resources":[],"examples":[{"caption":"<p>Encrypt a new table</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nkey_name = \"projects/a/locations/b/keyRings/c/cryptoKeys/d\"\nencrypt_config = bigquery.encryption kms_key: key_name\n\ntable = dataset.create_table \"my_table\" do |updater|\n  updater.encryption = encrypt_config\nend"},{"caption":"<p>Encrypt a load destination table</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nkey_name = \"projects/a/locations/b/keyRings/c/cryptoKeys/d\"\nencrypt_config = bigquery.encryption kms_key: key_name\njob = dataset.load_job \"my_table\", \"gs://abc/file\" do |job|\n  job.encryption = encrypt_config\nend"},{"caption":"<p>Encrypt a copy destination table</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nkey_name = \"projects/a/locations/b/keyRings/c/cryptoKeys/d\"\nencrypt_config = bigquery.encryption kms_key: key_name\njob = table.copy_job \"my_dataset.new_table\" do |job|\n  job.encryption = encrypt_config\nend"},{"caption":"<p>Encrypt a query destination table</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nkey_name = \"projects/a/locations/b/keyRings/c/cryptoKeys/d\"\nencrypt_config = bigquery.encryption kms_key: key_name\njob = bigquery.query_job \"SELECT 1;\" do |query|\n  query.table = dataset.table \"my_table\", skip_lookup: true\n  query.encryption = encrypt_config\nend"}],"params":[{"name":"kms_key","types":["String"],"description":"Name of the Cloud KMS encryption key that\nwill be used to protect the destination BigQuery table. The BigQuery\nService Account associated with your project requires access to this\nencryption key.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/encryptionconfiguration\">Google::Cloud::Bigquery::EncryptionConfiguration</a>"],"description":""}]}]}