{"id":"google/cloud/dataproc/v1/pysparkjob","name":"PySparkJob","title":["Google","Cloud","Dataproc","V1","PySparkJob"],"description":"<p>A Cloud Dataproc job for running\n<a href=\"https://spark.apache.org/docs/0.9.0/python-programming-guide.html\">Apache PySpark</a>\napplications on YARN.</p>","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"methods":[{"id":"main_python_file_uri-instance","type":"instance","name":"main_python_file_uri","title":["Google","Cloud","Dataproc","V1","PySparkJob#main_python_file_uri"],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"Required. The HCFS URI of the main Python file to use as the driver. Must\nbe a .py file."}]},{"id":"main_python_file_uri=-instance","type":"instance","name":"main_python_file_uri=","title":["Google","Cloud","Dataproc","V1","PySparkJob#main_python_file_uri="],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"Required. The HCFS URI of the main Python file to use as the driver. Must\nbe a .py file."}]},{"id":"args-instance","type":"instance","name":"args","title":["Google","Cloud","Dataproc","V1","PySparkJob#args"],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. The arguments to pass to the driver.  Do not include arguments,\nsuch as +–conf+, that can be set as job properties, since a collision may\noccur that causes an incorrect job submission."}]},{"id":"args=-instance","type":"instance","name":"args=","title":["Google","Cloud","Dataproc","V1","PySparkJob#args="],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. The arguments to pass to the driver.  Do not include arguments,\nsuch as +–conf+, that can be set as job properties, since a collision may\noccur that causes an incorrect job submission."}]},{"id":"python_file_uris-instance","type":"instance","name":"python_file_uris","title":["Google","Cloud","Dataproc","V1","PySparkJob#python_file_uris"],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. HCFS file URIs of Python files to pass to the PySpark\nframework. Supported file types: .py, .egg, and .zip."}]},{"id":"python_file_uris=-instance","type":"instance","name":"python_file_uris=","title":["Google","Cloud","Dataproc","V1","PySparkJob#python_file_uris="],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. HCFS file URIs of Python files to pass to the PySpark\nframework. Supported file types: .py, .egg, and .zip."}]},{"id":"jar_file_uris-instance","type":"instance","name":"jar_file_uris","title":["Google","Cloud","Dataproc","V1","PySparkJob#jar_file_uris"],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. HCFS URIs of jar files to add to the CLASSPATHs of the\nPython driver and tasks."}]},{"id":"jar_file_uris=-instance","type":"instance","name":"jar_file_uris=","title":["Google","Cloud","Dataproc","V1","PySparkJob#jar_file_uris="],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. HCFS URIs of jar files to add to the CLASSPATHs of the\nPython driver and tasks."}]},{"id":"file_uris-instance","type":"instance","name":"file_uris","title":["Google","Cloud","Dataproc","V1","PySparkJob#file_uris"],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. HCFS URIs of files to be copied to the working directory of\nPython drivers and distributed tasks. Useful for naively parallel tasks."}]},{"id":"file_uris=-instance","type":"instance","name":"file_uris=","title":["Google","Cloud","Dataproc","V1","PySparkJob#file_uris="],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. HCFS URIs of files to be copied to the working directory of\nPython drivers and distributed tasks. Useful for naively parallel tasks."}]},{"id":"archive_uris-instance","type":"instance","name":"archive_uris","title":["Google","Cloud","Dataproc","V1","PySparkJob#archive_uris"],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. HCFS URIs of archives to be extracted in the working directory of\n.jar, .tar, .tar.gz, .tgz, and .zip."}]},{"id":"archive_uris=-instance","type":"instance","name":"archive_uris=","title":["Google","Cloud","Dataproc","V1","PySparkJob#archive_uris="],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":"Optional. HCFS URIs of archives to be extracted in the working directory of\n.jar, .tar, .tar.gz, .tgz, and .zip."}]},{"id":"properties-instance","type":"instance","name":"properties","title":["Google","Cloud","Dataproc","V1","PySparkJob#properties"],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Hash{String =&gt; String}"],"description":"Optional. A mapping of property names to values, used to configure PySpark.\nProperties that conflict with values set by the Cloud Dataproc API may be\noverwritten. Can include properties set in\n/etc/spark/conf/spark-defaults.conf and classes in user code."}]},{"id":"properties=-instance","type":"instance","name":"properties=","title":["Google","Cloud","Dataproc","V1","PySparkJob#properties="],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Hash{String =&gt; String}"],"description":"Optional. A mapping of property names to values, used to configure PySpark.\nProperties that conflict with values set by the Cloud Dataproc API may be\noverwritten. Can include properties set in\n/etc/spark/conf/spark-defaults.conf and classes in user code."}]},{"id":"logging_config-instance","type":"instance","name":"logging_config","title":["Google","Cloud","Dataproc","V1","PySparkJob#logging_config"],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/dataproc/v1/loggingconfig\">Google::Cloud::Dataproc::V1::LoggingConfig</a>"],"description":"Optional. The runtime log config for job execution."}]},{"id":"logging_config=-instance","type":"instance","name":"logging_config=","title":["Google","Cloud","Dataproc","V1","PySparkJob#logging_config="],"description":"","source":"google-cloud-dataproc/lib/google/cloud/dataproc/v1/doc/google/cloud/dataproc/v1/jobs.rb#L180","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/dataproc/v1/loggingconfig\">Google::Cloud::Dataproc::V1::LoggingConfig</a>"],"description":"Optional. The runtime log config for job execution."}]}]}