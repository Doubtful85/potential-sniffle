{"id":"google/cloud/vision/image","name":"Image","title":["Google","Cloud","Vision","Image"],"description":"<h1 id=\"image\">Image</h1>\n\n<p>Represents an image for the Vision service.</p>\n\n<p>An Image instance can be created from a string file path, publicly-\naccessible image HTTP/HTTPS URL, or Cloud Storage URI of the form\n<code>\"gs://bucketname/path/to/image_filename\"</code>; or a File, IO, StringIO, or\nTempfile instance; or an instance of Google::Cloud::Storage::File.</p>\n\n<p>See <a data-custom-type=\"google/cloud/vision/project\" data-method=\"image-instance\">Project#image</a>.</p>\n\n<p>The Cloud Vision API supports a variety of image file formats, including\nJPEG, PNG8, PNG24, Animated GIF (first frame only), and RAW. See <a href=\"https://cloud.google.com/vision/docs/best-practices#image_types\">Best\nPractices - Image\nTypes</a>\nfor the list of formats. Be aware that Cloud Vision sets upper limits on\nfile size as well as the total combined size of all images in a request.\nReducing your file size can significantly improve throughput; however,\nbe careful not to reduce image quality in the process. See <a href=\"https://cloud.google.com/vision/docs/best-practices#image_sizing\">Best\nPractices - Image\nSizing</a>\nfor current file size limits.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L62","resources":[{"title":"Best\nPractices","link":"https://cloud.google.com/vision/docs/best-practices"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\n\nimage = vision.image \"path/to/text.png\"\n\nimage.context.languages = [\"en\"]\n\ntext = image.text\ntext.pages.count #=> 1"}],"methods":[{"id":"context-instance","type":"instance","name":"context","title":["Google","Cloud","Vision","Image#context"],"description":"<p>Returns the image context for the image, which accepts metadata values\nsuch as location and language hints.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L66","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/image/context\">Context</a>"],"description":"The context instance for the image."}]},{"id":"faces-instance","type":"instance","name":"faces","title":["Google","Cloud","Vision","Image#faces"],"description":"<p>Performs the <code>FACE_DETECTION</code> feature on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L115","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/face.jpg\"\n\nfaces = image.faces\n\nface = faces.first\nface.bounds.face.count #=> 4\nvertex = face.bounds.face.first\nvertex.x #=> 28\nvertex.y #=> 40"}],"params":[{"name":"max_results","types":["Integer"],"description":"The maximum number of results. The\ndefault is Google::Cloud::Vision.default_max_faces. Optional.","optional":true,"default":"Vision.default_max_faces","nullable":false}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/vision/annotation/face\">Annotation::Face</a>&gt;"],"description":"The results of face detection."}]},{"id":"face-instance","type":"instance","name":"face","title":["Google","Cloud","Vision","Image#face"],"description":"<p>Performs the <code>FACE_DETECTION</code> feature on the image and returns only\nthe first result.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L127","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation/face\">Annotation::Face</a>"],"description":"The first result of face detection."}]},{"id":"landmarks-instance","type":"instance","name":"landmarks","title":["Google","Cloud","Vision","Image#landmarks"],"description":"<p>Performs the <code>LANDMARK_DETECTION</code> feature on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L154","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/landmark.jpg\"\n\nlandmarks = image.landmarks\n\nlandmark = landmarks.first\nlandmark.score #=> 0.9191226363182068\nlandmark.description #=> \"Mount Rushmore\"\nlandmark.mid #=> \"/m/019dvv\""}],"params":[{"name":"max_results","types":["Integer"],"description":"The maximum number of results. The\ndefault is Google::Cloud::Vision.default_max_landmarks. Optional.","optional":true,"default":"Vision.default_max_landmarks","nullable":false}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/vision/annotation/entity\">Annotation::Entity</a>&gt;"],"description":"The results of landmark detection."}]},{"id":"landmark-instance","type":"instance","name":"landmark","title":["Google","Cloud","Vision","Image#landmark"],"description":"<p>Performs the <code>LANDMARK_DETECTION</code> feature on the image and returns\nonly the first result.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L166","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation/entity\">Annotation::Entity</a>"],"description":"The first result of landmark detection."}]},{"id":"logos-instance","type":"instance","name":"logos","title":["Google","Cloud","Vision","Image#logos"],"description":"<p>Performs the <code>LOGO_DETECTION</code> feature on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L193","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/logo.jpg\"\n\nlogos = image.logos\n\nlogo = logos.first\nlogo.score #=> 0.7005731463432312\nlogo.description #=> \"Google\"\nlogo.mid #=> \"/m/0b34hf\""}],"params":[{"name":"max_results","types":["Integer"],"description":"The maximum number of results. The\ndefault is Google::Cloud::Vision.default_max_logos. Optional.","optional":true,"default":"Vision.default_max_logos","nullable":false}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/vision/annotation/entity\">Annotation::Entity</a>&gt;"],"description":"The results of logo detection."}]},{"id":"logo-instance","type":"instance","name":"logo","title":["Google","Cloud","Vision","Image#logo"],"description":"<p>Performs the <code>LOGO_DETECTION</code> feature on the image and returns only\nthe first result.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L205","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation/entity\">Annotation::Entity</a>"],"description":"The first result of logo detection."}]},{"id":"labels-instance","type":"instance","name":"labels","title":["Google","Cloud","Vision","Image#labels"],"description":"<p>Performs the <code>LABEL_DETECTION</code> feature on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L233","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/landmark.jpg\"\n\nlabels = image.labels\n\nlabels.count #=> 4\nlabel = labels.first\nlabel.score #=> 0.9481348991394043\nlabel.description #=> \"stone carving\"\nlabel.mid #=> \"/m/02wtjj\""}],"params":[{"name":"max_results","types":["Integer"],"description":"The maximum number of results. The\ndefault is Google::Cloud::Vision.default_max_labels. Optional.","optional":true,"default":"Vision.default_max_labels","nullable":false}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/vision/annotation/entity\">Annotation::Entity</a>&gt;"],"description":"The results of label detection."}]},{"id":"label-instance","type":"instance","name":"label","title":["Google","Cloud","Vision","Image#label"],"description":"<p>Performs the <code>LABEL_DETECTION</code> feature on the image and returns only\nthe first result.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L245","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation/entity\">Annotation::Entity</a>"],"description":"The first result of label detection."}]},{"id":"text-instance","type":"instance","name":"text","title":["Google","Cloud","Vision","Image#text"],"description":"<p>Performs the <code>TEXT_DETECTION</code> feature (OCR for shorter documents with\nsparse text) on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L281","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/text.png\"\n\ntext = image.text\n\ntext.text\n# \"Google Cloud Client for Ruby an idiomatic, intuitive... \"\n\ntext.locale #=> \"en\"\ntext.words.count #=> 28\ntext.words[0].text #=> \"Google\"\ntext.words[0].bounds.count #=> 4\nvertex = text.words[0].bounds.first\nvertex.x #=> 13\nvertex.y #=> 8\n\n# Use `pages` to access a full structural representation\npage = text.pages.first\npage.blocks[0].paragraphs[0].words[0].symbols[0].text #=> \"G\""}],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation/text\">Annotation::Text</a>"],"description":"The results of text (OCR) detection."}]},{"id":"document-instance","type":"instance","name":"document","title":["Google","Cloud","Vision","Image#document"],"description":"<p>Performs the <code>DOCUMENT_TEXT_DETECTION</code> feature (OCR for longer\ndocuments with dense text) on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L317","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/text.png\"\n\ntext = image.document\n\ntext.text\n# \"Google Cloud Client for Ruby an idiomatic, intuitive... \"\n\ntext.words[0].text #=> \"Google\"\ntext.words[0].bounds.count #=> 4\nvertex = text.words[0].bounds.first\nvertex.x #=> 13\nvertex.y #=> 8\n\n# Use `pages` to access a full structural representation\npage = text.pages.first\npage.blocks[0].paragraphs[0].words[0].symbols[0].text #=> \"G\""}],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation/text\">Annotation::Text</a>"],"description":"The results of document text (OCR)\ndetection."}]},{"id":"safe_search-instance","type":"instance","name":"safe_search","title":["Google","Cloud","Vision","Image#safe_search"],"description":"<p>Performs the <code>SAFE_SEARCH_DETECTION</code> feature on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L341","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/face.jpg\"\n\nsafe_search = image.safe_search\n\nsafe_search.spoof? #=> false\nsafe_search.spoof #=> :VERY_UNLIKELY"}],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation/safesearch\">Annotation::SafeSearch</a>"],"description":"The results of safe search detection."}]},{"id":"properties-instance","type":"instance","name":"properties","title":["Google","Cloud","Vision","Image#properties"],"description":"<p>Performs the <code>IMAGE_PROPERTIES</code> feature on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L369","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/logo.jpg\"\n\nproperties = image.properties\n\nproperties.colors.count #=> 10\ncolor = properties.colors.first\ncolor.red #=> 247.0\ncolor.green #=> 236.0\ncolor.blue #=> 20.0"}],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation/properties\">Annotation::Properties</a>"],"description":"The results of image properties\ndetection."}]},{"id":"crop_hints-instance","type":"instance","name":"crop_hints","title":["Google","Cloud","Vision","Image#crop_hints"],"description":"<p>Performs the <code>CROP_HINTS</code> feature on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L397","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/face.jpg\"\n\ncrop_hints = image.crop_hints\ncrop_hints.count #=> 1\ncrop_hint = crop_hints.first\n\ncrop_hint.bounds.count #=> 4\ncrop_hint.confidence #=> 1.0\ncrop_hint.importance_fraction #=> 1.0399999618530273"}],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/vision/annotation/crophint\">Annotation::CropHint</a>&gt;"],"description":"The results of crop hints\ndetection."}]},{"id":"web-instance","type":"instance","name":"web","title":["Google","Cloud","Vision","Image#web"],"description":"<p>Performs the <code>WEB_ANNOTATION</code> feature on the image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L431","resources":[{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\nimage = vision.image \"path/to/face.jpg\"\n\nweb = image.web\n\nentity = web.entities.first\nentity.entity_id #=> \"/m/019dvv\"\nentity.score #=> 107.34591674804688\nentity.description #=> \"Mount Rushmore National Memorial\"\n\nfull_matching_image = web.full_matching_images.first\nfull_matching_image.url #=> \"http://example.com/images/123.jpg\"\nfull_matching_image.score #=> 0.10226666927337646\n\npage_with_matching_images = web.pages_with_matching_images.first\npage_with_matching_images.url #=> \"http://example.com/posts/123\"\npage_with_matching_images.score #=> 8.114753723144531"}],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation/web\">Annotation::Web</a>"],"description":"The results of web detection."}]},{"id":"annotate-instance","type":"instance","name":"annotate","title":["Google","Cloud","Vision","Image#annotate"],"description":"<p>Performs detection of Cloud Vision\n<a href=\"https://cloud.google.com/vision/reference/rest/v1/images/annotate#Feature\">features</a>\non the image. If no options for features are provided, <strong>all</strong> image\ndetection features will be performed, with a default of <code>100</code> results\nfor faces, landmarks, logos, labels, crop_hints, and web. If any\nfeature option is provided, only the specified feature detections will\nbe performed. Please review\n<a href=\"https://cloud.google.com/vision/docs/pricing\">Pricing</a> before use, as\na separate charge is incurred for each feature performed on an image.</p>","source":"google-cloud-vision/lib/google/cloud/vision/image.rb#L514","resources":[{"title":"Cloud\nVision API Requests and Responses","link":"https://cloud.google.com/vision/docs/requests-and-responses"},{"title":"AnnotateImageRequest","link":"https://cloud.google.com/vision/reference/rest/v1/images/annotate#AnnotateImageRequest"},{"title":"Cloud Vision Pricing","link":"https://cloud.google.com/vision/docs/pricing"}],"examples":[{"caption":"","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\n\nimage = vision.image \"path/to/landmark.jpg\"\n\nannotation = image.annotate labels: true, landmarks: true\n\nannotation.labels.map &:description\n# [\"stone carving\", \"ancient history\", \"statue\", \"sculpture\",\n#  \"monument\", \"landmark\"]\nannotation.landmarks.count #=> 1"},{"caption":"<p>Maximum result values can also be provided:</p>","code":"require \"google/cloud/vision\"\n\nvision = Google::Cloud::Vision.new\n\nimage = vision.image \"path/to/landmark.jpg\"\n\nannotation = image.annotate labels: 3, landmarks: 3\n\nannotation.labels.map &:description\n# [\"stone carving\", \"ancient history\", \"statue\"]\nannotation.landmarks.count #=> 1"}],"params":[{"name":"faces","types":["Boolean","Integer"],"description":"Whether to perform the facial\ndetection feature. The maximum number of results is configured in\nGoogle::Cloud::Vision.default_max_faces, or may be provided here.\nOptional.","optional":true,"default":"false","nullable":false},{"name":"landmarks","types":["Boolean","Integer"],"description":"Whether to perform the landmark\ndetection feature. The maximum number of results is configured in\nGoogle::Cloud::Vision.default_max_landmarks, or may be provided\nhere. Optional.","optional":true,"default":"false","nullable":false},{"name":"logos","types":["Boolean","Integer"],"description":"Whether to perform the logo detection\nfeature. The maximum number of results is configured in\nGoogle::Cloud::Vision.default_max_logos, or may be provided here.\nOptional.","optional":true,"default":"false","nullable":false},{"name":"labels","types":["Boolean","Integer"],"description":"Whether to perform the label\ndetection feature. The maximum number of results is configured in\nGoogle::Cloud::Vision.default_max_labels, or may be provided here.\nOptional.","optional":true,"default":"false","nullable":false},{"name":"text","types":["Boolean"],"description":"Whether to perform the text detection feature\n(OCR for shorter documents with sparse text). Optional.","optional":true,"default":"false","nullable":false},{"name":"document","types":["Boolean"],"description":"Whether to perform the document text\ndetection feature (OCR for longer documents with dense text).\nOptional.","optional":true,"default":"false","nullable":false},{"name":"safe_search","types":["Boolean"],"description":"Whether to perform the safe search\nfeature. Optional.","optional":true,"default":"false","nullable":false},{"name":"properties","types":["Boolean"],"description":"Whether to perform the image properties\nfeature (currently, the image’s dominant colors.) Optional.","optional":true,"default":"false","nullable":false},{"name":"crop_hints","types":["Boolean","Integer"],"description":"Whether to perform the crop hints\nfeature. Optional.","optional":true,"default":"false","nullable":false},{"name":"web","types":["Boolean","Integer"],"description":"Whether to perform the web annotation\nfeature. Optional.","optional":true,"default":"false","nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/vision/annotation\">Annotation</a>"],"description":"The results for all image detections, returned as\na single <a data-custom-type=\"google/cloud/vision/annotation\">Annotation</a> instance."}]}]}