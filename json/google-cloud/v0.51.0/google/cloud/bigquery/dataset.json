{"id":"google/cloud/bigquery/dataset","name":"Dataset","title":["Google","Cloud","Bigquery","Dataset"],"description":"<h1 id=\"dataset\">Dataset</h1>\n\n<p>Represents a Dataset. A dataset is a grouping mechanism that holds zero\nor more tables. Datasets are the lowest level unit of access control;\nyou cannot control access at the table level. A dataset is contained\nwithin a specific project.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L45","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.create_dataset \"my_dataset\",\n                                  name: \"My Dataset\",\n                                  description: \"This is my Dataset\""}],"methods":[{"id":"dataset_id-instance","type":"instance","name":"dataset_id","title":["Google","Cloud","Bigquery","Dataset#dataset_id"],"description":"<p>A unique ID for this dataset, without the project name.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L74","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The ID must contain only letters (a-z, A-Z), numbers\n(0-9), or underscores (_). The maximum length is 1,024 characters."}]},{"id":"project_id-instance","type":"instance","name":"project_id","title":["Google","Cloud","Bigquery","Dataset#project_id"],"description":"<p>The ID of the project containing this dataset.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L86","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"The project ID."}]},{"id":"name-instance","type":"instance","name":"name","title":["Google","Cloud","Bigquery","Dataset#name"],"description":"<p>A descriptive name for the dataset.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L109","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String","nil"],"description":"The friendly name, or <code>nil</code> if the object is\na reference (see <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>)."}]},{"id":"name=-instance","type":"instance","name":"name=","title":["Google","Cloud","Bigquery","Dataset#name="],"description":"<p>Updates the descriptive name for the dataset.</p>\n\n<p>If the dataset is not a full resource representation (see\n<a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"resource_full?-instance\">#resource_full?</a>), the full representation will be retrieved before\nthe update to comply with ETag-based optimistic concurrency control.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L126","resources":[],"examples":[],"params":[{"name":"new_name","types":["String"],"description":"The new friendly name, or <code>nil</code> if the object\nis a reference (see <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>).","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"etag-instance","type":"instance","name":"etag","title":["Google","Cloud","Bigquery","Dataset#etag"],"description":"<p>The ETag hash of the dataset.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L140","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String","nil"],"description":"The ETag hash, or <code>nil</code> if the object is a\nreference (see <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>)."}]},{"id":"api_url-instance","type":"instance","name":"api_url","title":["Google","Cloud","Bigquery","Dataset#api_url"],"description":"<p>A URL that can be used to access the dataset using the REST API.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L154","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String","nil"],"description":"A REST URL for the resource, or <code>nil</code> if the\nobject is a reference (see <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>)."}]},{"id":"description-instance","type":"instance","name":"description","title":["Google","Cloud","Bigquery","Dataset#description"],"description":"<p>A user-friendly description of the dataset.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L168","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String","nil"],"description":"The description, or <code>nil</code> if the object is a\nreference (see <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>)."}]},{"id":"description=-instance","type":"instance","name":"description=","title":["Google","Cloud","Bigquery","Dataset#description="],"description":"<p>Updates the user-friendly description of the dataset.</p>\n\n<p>If the dataset is not a full resource representation (see\n<a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"resource_full?-instance\">#resource_full?</a>), the full representation will be retrieved before\nthe update to comply with ETag-based optimistic concurrency control.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L185","resources":[],"examples":[],"params":[{"name":"new_description","types":["String"],"description":"The new description for the dataset.","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"default_expiration-instance","type":"instance","name":"default_expiration","title":["Google","Cloud","Bigquery","Dataset#default_expiration"],"description":"<p>The default lifetime of all tables in the dataset, in milliseconds.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L200","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Integer","nil"],"description":"The default table expiration in milliseconds,\nor <code>nil</code> if not present or the object is a reference (see\n<a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>)."}]},{"id":"default_expiration=-instance","type":"instance","name":"default_expiration=","title":["Google","Cloud","Bigquery","Dataset#default_expiration="],"description":"<p>Updates the default lifetime of all tables in the dataset, in\nmilliseconds.</p>\n\n<p>If the dataset is not a full resource representation (see\n<a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"resource_full?-instance\">#resource_full?</a>), the full representation will be retrieved before\nthe update to comply with ETag-based optimistic concurrency control.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L223","resources":[],"examples":[],"params":[{"name":"new_default_expiration","types":["Integer"],"description":"The new default table\nexpiration in milliseconds.","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"created_at-instance","type":"instance","name":"created_at","title":["Google","Cloud","Bigquery","Dataset#created_at"],"description":"<p>The time when this dataset was created.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L237","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/time\">Time</a>","nil"],"description":"The creation time, or <code>nil</code> if not present or the\nobject is a reference (see <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>)."}]},{"id":"modified_at-instance","type":"instance","name":"modified_at","title":["Google","Cloud","Bigquery","Dataset#modified_at"],"description":"<p>The date when this dataset or any of its tables was last modified.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L255","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/time\">Time</a>","nil"],"description":"The last modified time, or <code>nil</code> if not present or\nthe object is a reference (see <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>)."}]},{"id":"location-instance","type":"instance","name":"location","title":["Google","Cloud","Bigquery","Dataset#location"],"description":"<p>The geographic location where the dataset should reside. Possible\nvalues include <code>EU</code> and <code>US</code>. The default value is <code>US</code>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L274","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String","nil"],"description":"The location code, or <code>nil</code> if the object is a\nreference (see <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>)."}]},{"id":"labels-instance","type":"instance","name":"labels","title":["Google","Cloud","Bigquery","Dataset#labels"],"description":"<p>A hash of user-provided labels associated with this dataset. Labels\nare used to organize and group datasets. See <a href=\"https://cloud.google.com/bigquery/docs/labels\">Using\nLabels</a>.</p>\n\n<p>The returned hash is frozen and changes are not allowed. Use\n<a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"labels=-instance\">#labels=</a> to replace the entire hash.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L302","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nlabels = dataset.labels\nlabels[\"department\"] #=> \"shipping\""}],"params":[],"exceptions":[],"returns":[{"types":["Hash&lt;String, String&gt;","nil"],"description":"A hash containing key/value pairs,\nor <code>nil</code> if the object is a reference (see <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"reference?-instance\">#reference?</a>)."}]},{"id":"labels=-instance","type":"instance","name":"labels=","title":["Google","Cloud","Bigquery","Dataset#labels="],"description":"<p>Updates the hash of user-provided labels associated with this dataset.\nLabels are used to organize and group datasets. See <a href=\"https://cloud.google.com/bigquery/docs/labels\">Using\nLabels</a>.</p>\n\n<p>If the dataset is not a full resource representation (see\n<a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"resource_full?-instance\">#resource_full?</a>), the full representation will be retrieved before\nthe update to comply with ETag-based optimistic concurrency control.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L338","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ndataset.labels = { \"department\" => \"shipping\" }"}],"params":[{"name":"labels","types":["Hash<String, String>"],"description":"A hash containing key/value\npairs.</p>\n\n<ul>\n  <li>Label keys and values can be no longer than 63 characters.</li>\n  <li>Label keys and values can contain only lowercase letters, numbers,\nunderscores, hyphens, and international characters.</li>\n  <li>Label keys and values cannot exceed 128 bytes in size.</li>\n  <li>Label keys must begin with a letter.</li>\n  <li>Label keys must be unique within a dataset.</li>\n</ul>","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"access-instance","type":"instance","name":"access","title":["Google","Cloud","Bigquery","Dataset#access"],"description":"<p>Retrieves the access rules for a Dataset. The rules can be updated\nwhen passing a block, see <a data-custom-type=\"google/cloud/bigquery/dataset/access\">Dataset::Access</a> for all the methods\navailable.</p>\n\n<p>If the dataset is not a full resource representation (see\n<a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"resource_full?-instance\">#resource_full?</a>), the full representation will be retrieved before\nthe update to comply with ETag-based optimistic concurrency control.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L384","resources":[{"title":"BigQuery Access\nControl","link":"https://cloud.google.com/bigquery/access-control"}],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\naccess = dataset.access\naccess.writer_user? \"reader@example.com\" #=> false"},{"caption":"<p>Manage the access rules by passing a block:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ndataset.access do |access|\n  access.add_owner_group \"owners@example.com\"\n  access.add_writer_user \"writer@example.com\"\n  access.remove_writer_user \"readers@example.com\"\n  access.add_reader_special :all\n  access.add_reader_view other_dataset_view_object\nend"}],"params":[{"name":"yield","types":["block"],"description":"a block for setting rules","optional":true,"nullable":false},{"name":"yield.access","types":["Dataset::Access"],"description":"the object accepting rules","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/dataset/access\">Google::Cloud::Bigquery::Dataset::Access</a>"],"description":"The access object."}]},{"id":"delete-instance","type":"instance","name":"delete","title":["Google","Cloud","Bigquery","Dataset#delete"],"description":"<p>Permanently deletes the dataset. The dataset must be empty before it\ncan be deleted unless the <code>force</code> option is set to <code>true</code>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L418","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ndataset.delete"}],"params":[{"name":"force","types":["Boolean"],"description":"If <code>true</code>, delete all the tables in the\ndataset. If <code>false</code> and the dataset contains tables, the request\nwill fail. Default is <code>false</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Boolean"],"description":"Returns <code>true</code> if the dataset was deleted."}]},{"id":"create_table-instance","type":"instance","name":"create_table","title":["Google","Cloud","Bigquery","Dataset#create_table"],"description":"<p>Creates a new table. If you are adapting existing code that was\nwritten for the <a href=\"https://cloud.google.com/bigquery/docs/reference/v2/tables#resource\">Rest API\n</a>,\nyou can pass the table’s schema as a hash (see example.)</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L492","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ntable = dataset.create_table \"my_table\""},{"caption":"<p>You can also pass name and description options.</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ntable = dataset.create_table \"my_table\",\n                             name: \"My Table\",\n                             description: \"A description of table.\""},{"caption":"<p>Or the table’s schema can be configured with the block.</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ntable = dataset.create_table \"my_table\" do |t|\n  t.schema.string \"first_name\", mode: :required\n  t.schema.record \"cities_lived\", mode: :required do |s|\n    s.string \"place\", mode: :required\n    s.integer \"number_of_years\", mode: :required\n  end\nend"},{"caption":"<p>You can define the schema using a nested block.</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ntable = dataset.create_table \"my_table\" do |t|\n  t.name = \"My Table\",\n  t.description = \"A description of my table.\"\n  t.schema do |s|\n    s.string \"first_name\", mode: :required\n    s.record \"cities_lived\", mode: :repeated do |r|\n      r.string \"place\", mode: :required\n      r.integer \"number_of_years\", mode: :required\n    end\n  end\nend"}],"params":[{"name":"table_id","types":["String"],"description":"The ID of the table. The ID must contain only\nletters (a-z, A-Z), numbers (0-9), or underscores (_). The maximum\nlength is 1,024 characters.","optional":false,"nullable":false},{"name":"name","types":["String"],"description":"A descriptive name for the table.","optional":true,"default":"nil","nullable":true},{"name":"description","types":["String"],"description":"A user-friendly description of the table.","optional":true,"default":"nil","nullable":true},{"name":"yield","types":["block"],"description":"a block for setting the table","optional":true,"nullable":false},{"name":"yield.table","types":["Table"],"description":"the table object to be updated","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/table\">Google::Cloud::Bigquery::Table</a>"],"description":"A new table object."}]},{"id":"create_view-instance","type":"instance","name":"create_view","title":["Google","Cloud","Bigquery","Dataset#create_view"],"description":"<p>Creates a new <a href=\"https://cloud.google.com/bigquery/docs/views\">view</a>\ntable, which is a virtual table defined by the given SQL query.</p>\n\n<p>BigQuery’s views are logical views, not materialized views, which\nmeans that the query that defines the view is re-executed every time\nthe view is queried. Queries are billed according to the total amount\nof data in all table fields referenced directly or indirectly by the\ntop-level query. (See <a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"view?-instance\">Table#view?</a> and <a data-custom-type=\"google/cloud/bigquery/table\" data-method=\"query-instance\">Table#query</a>.)</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L567","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nview = dataset.create_view \"my_view\",\n          \"SELECT name, age FROM proj.dataset.users\""},{"caption":"<p>A name and description can be provided:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nview = dataset.create_view \"my_view\",\n          \"SELECT name, age FROM proj.dataset.users\",\n          name: \"My View\", description: \"This is my view\""}],"params":[{"name":"table_id","types":["String"],"description":"The ID of the view table. The ID must contain\nonly letters (a-z, A-Z), numbers (0-9), or underscores (_). The\nmaximum length is 1,024 characters.","optional":false,"nullable":false},{"name":"query","types":["String"],"description":"The query that BigQuery executes when the view\nis referenced.","optional":false,"nullable":false},{"name":"name","types":["String"],"description":"A descriptive name for the table.","optional":true,"default":"nil","nullable":true},{"name":"description","types":["String"],"description":"A user-friendly description of the table.","optional":true,"default":"nil","nullable":true},{"name":"standard_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\ndialect. Optional. The default value is true.","optional":true,"default":"nil","nullable":true},{"name":"legacy_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect. Optional. The default value is false.","optional":true,"default":"nil","nullable":true},{"name":"udfs","types":["Array<String>","String"],"description":"User-defined function resources\nused in the query. May be either a code resource to load from a\nGoogle Cloud Storage URI (<code>gs://bucket/path</code>), or an inline resource\nthat contains code for a user-defined function (UDF). Providing an\ninline code resource is equivalent to providing a URI for a file\ncontaining the same code. See <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/user-defined-functions\">User-Defined\nFunctions</a>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/table\">Google::Cloud::Bigquery::Table</a>"],"description":"A new table object."}]},{"id":"table-instance","type":"instance","name":"table","title":["Google","Cloud","Bigquery","Dataset#table"],"description":"<p>Retrieves an existing table by ID.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L620","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ntable = dataset.table \"my_table\"\nputs table.name"},{"caption":"<p>Avoid retrieving the table resource with <code>skip_lookup</code>:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\"\n\ntable = dataset.table \"my_table\", skip_lookup: true"}],"params":[{"name":"table_id","types":["String"],"description":"The ID of a table.","optional":false,"nullable":false},{"name":"skip_lookup","types":["Boolean"],"description":"Optionally create just a local reference\nobject without verifying that the resource exists on the BigQuery\nservice. Calls made on this object will raise errors if the resource\ndoes not exist. Default is <code>false</code>. Optional.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/table\">Google::Cloud::Bigquery::Table</a>","nil"],"description":"Returns <code>nil</code> if the\ntable does not exist."}]},{"id":"tables-instance","type":"instance","name":"tables","title":["Google","Cloud","Bigquery","Dataset#tables"],"description":"<p>Retrieves the list of tables belonging to the dataset.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L665","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ntables = dataset.tables\ntables.each do |table|\n  puts table.name\nend"},{"caption":"<p>Retrieve all tables: (See <a data-custom-type=\"google/cloud/bigquery/table/list\" data-method=\"all-instance\">Table::List#all</a>)</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ntables = dataset.tables\ntables.all do |table|\n  puts table.name\nend"}],"params":[{"name":"token","types":["String"],"description":"A previously-returned page token representing\npart of the larger set of results to view.","optional":true,"default":"nil","nullable":true},{"name":"max","types":["Integer"],"description":"Maximum number of tables to return.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/bigquery/table\">Google::Cloud::Bigquery::Table</a>&gt;"],"description":"An array of tables\n(See <a data-custom-type=\"google/cloud/bigquery/table/list\">Google::Cloud::Bigquery::Table::List</a>)"}]},{"id":"query_job-instance","type":"instance","name":"query_job","title":["Google","Cloud","Bigquery","Dataset#query_job"],"description":"<p>Queries data by creating a <a href=\"https://cloud.google.com/bigquery/docs/query-overview#query_jobs\">query\njob</a>.</p>\n\n<p>Sets the current dataset as the default dataset in the query. Useful\nfor using unqualified table names.</p>\n\n<p>When using standard SQL and passing arguments using <code>params</code>, Ruby\ntypes are mapped to BigQuery types as follows:</p>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th>BigQuery</th>\n      <th>Ruby</th>\n      <th>Notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><code>BOOL</code></td>\n      <td><code>true</code>/<code>false</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>INT64</code></td>\n      <td><code>Integer</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>FLOAT64</code></td>\n      <td><code>Float</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>STRING</code></td>\n      <td><code>STRING</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>DATETIME</code></td>\n      <td><code>DateTime</code></td>\n      <td><code>DATETIME</code> does not support time zone.</td>\n    </tr>\n    <tr>\n      <td><code>DATE</code></td>\n      <td><code>Date</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>TIMESTAMP</code></td>\n      <td><code>Time</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>TIME</code></td>\n      <td><code>Google::Cloud::BigQuery::Time</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>BYTES</code></td>\n      <td><code>File</code>, <code>IO</code>, <code>StringIO</code>, or similar</td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>ARRAY</code></td>\n      <td><code>Array</code></td>\n      <td>Nested arrays, <code>nil</code> values are not supported.</td>\n    </tr>\n    <tr>\n      <td><code>STRUCT</code></td>\n      <td><code>Hash</code></td>\n      <td>Hash keys may be strings or symbols.</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types\">Data Types</a>\nfor an overview of each BigQuery data type, including allowed values.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L892","resources":[],"examples":[{"caption":"<p>Query using standard SQL:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\njob = dataset.query_job \"SELECT name FROM my_table\"\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"},{"caption":"<p>Query using legacy SQL:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\njob = dataset.query_job \"SELECT name FROM my_table\",\n                        legacy_sql: true\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"},{"caption":"<p>Query using positional query parameters:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\njob = dataset.query_job \"SELECT name FROM my_table WHERE id = ?\",\n                        params: [1]\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"},{"caption":"<p>Query using named query parameters:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\njob = dataset.query_job \"SELECT name FROM my_table WHERE id = @id\",\n                        params: { id: 1 }\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"},{"caption":"<p>Query using external data source:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = dataset.external csv_url do |csv|\n  csv.autodetect = true\n  csv.skip_leading_rows = 1\nend\n\njob = dataset.query_job \"SELECT * FROM my_ext_table\",\n                        external: { my_ext_table: csv_table }\n\njob.wait_until_done!\nif !job.failed?\n  job.data.each do |row|\n    puts row[:name]\n  end\nend"}],"params":[{"name":"query","types":["String"],"description":"A query string, following the BigQuery <a href=\"https://cloud.google.com/bigquery/query-reference\">query\nsyntax</a>, of the\nquery to execute. Example: “SELECT count(f1) FROM\n[myProjectId:myDatasetId.myTableId]”.","optional":false,"nullable":false},{"name":"params","types":["Array","Hash"],"description":"Standard SQL only. Used to pass query\narguments when the <code>query</code> string contains either positional (<code>?</code>)\nor named (<code>@myparam</code>) query parameters. If value passed is an array\n<code>[\"foo\"]</code>, the query must use positional query parameters. If value\npassed is a hash <code>{ myparam: \"foo\" }</code>, the query must use named\nquery parameters. When set, <code>legacy_sql</code> will automatically be set\nto false and <code>standard_sql</code> to true.","optional":true,"default":"nil","nullable":true},{"name":"external","types":["Hash<String|Symbol, External::DataSource>"],"description":"A Hash\nthat represents the mapping of the external tables to the table\nnames used in the SQL query. The hash keys are the table names, and\nthe hash values are the external table objects. See <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"query-instance\">Dataset#query</a>.","optional":true,"default":"nil","nullable":true},{"name":"priority","types":["String"],"description":"Specifies a priority for the query. Possible\nvalues include <code>INTERACTIVE</code> and <code>BATCH</code>. The default value is\n<code>INTERACTIVE</code>.","optional":true,"default":"\"INTERACTIVE\"","nullable":false},{"name":"cache","types":["Boolean"],"description":"Whether to look for the result in the query\ncache. The query cache is a best-effort cache that will be flushed\nwhenever tables in the query are modified. The default value is\ntrue. For more information, see <a href=\"https://developers.google.com/bigquery/querying-data\">query\ncaching</a>.","optional":true,"default":"true","nullable":false},{"name":"table","types":["Table"],"description":"The destination table where the query results\nshould be stored. If not present, a new table will be created to\nstore the results.","optional":true,"default":"nil","nullable":true},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables. The default value is <code>needed</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies the action that occurs if the\ndestination table already exists. The default value is <code>empty</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - A ‘duplicate’ error is returned in the job result if the\ntable exists and contains data.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"standard_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\ndialect for this query. If set to true, the query will use standard\nSQL rather than the <a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect. Optional. The default value is true.","optional":true,"default":"nil","nullable":true},{"name":"legacy_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect for this query. If set to false, the query will use\nBigQuery’s <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\ndialect. Optional. The default value is false.","optional":true,"default":"nil","nullable":true},{"name":"large_results","types":["Boolean"],"description":"This option is specific to Legacy SQL.\nIf <code>true</code>, allows the query to produce arbitrarily large result\ntables at a slight cost in performance. Requires <code>table</code> parameter\nto be set.","optional":true,"default":"nil","nullable":true},{"name":"flatten","types":["Boolean"],"description":"This option is specific to Legacy SQL.\nFlattens all nested and repeated fields in the query results. The\ndefault value is <code>true</code>. <code>large_results</code> parameter must be <code>true</code> if\nthis is set to <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"maximum_billing_tier","types":["Integer"],"description":"Limits the billing tier for this\njob. Queries that have resource usage beyond this tier will fail\n(without incurring a charge). Optional. If unspecified, this will be\nset to your project default. For more information, see <a href=\"https://cloud.google.com/bigquery/pricing#high-compute\">High-Compute\nqueries</a>.","optional":true,"default":"nil","nullable":true},{"name":"maximum_bytes_billed","types":["Integer"],"description":"Limits the bytes billed for this\njob. Queries that will have bytes billed beyond this limit will fail\n(without incurring a charge). Optional. If unspecified, this will be\nset to your project default.","optional":true,"default":"nil","nullable":true},{"name":"job_id","types":["String"],"description":"A user-defined ID for the query job. The ID\nmust contain only letters (a-z, A-Z), numbers (0-9), underscores\n(_), or dashes (-). The maximum length is 1,024 characters. If\n<code>job_id</code> is provided, then <code>prefix</code> will not be used.</p>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/managing-jobs#generate-jobid\">Generating a job\nID</a>.","optional":true,"default":"nil","nullable":true},{"name":"prefix","types":["String"],"description":"A string, usually human-readable, that will be\nprepended to a generated value to produce a unique job ID. For\nexample, the prefix <code>daily_import_job_</code> can be given to generate a\njob ID such as <code>daily_import_job_12vEDtMQ0mbp1Mo5Z7mzAFQJZazh</code>. The\nprefix must contain only letters (a-z, A-Z), numbers (0-9),\nunderscores (_), or dashes (-). The maximum length of the entire ID\nis 1,024 characters. If <code>job_id</code> is provided, then <code>prefix</code> will not\nbe used.","optional":true,"default":"nil","nullable":true},{"name":"labels","types":["Hash"],"description":"A hash of user-provided labels associated with\nthe job. You can use these to organize and group your jobs. Label\nkeys and values can be no longer than 63 characters, can only\ncontain lowercase letters, numeric characters, underscores and\ndashes. International characters are allowed. Label values are\noptional. Label keys must start with a letter and each label in the\nlist must have a different key.","optional":true,"default":"nil","nullable":true},{"name":"udfs","types":["Array<String>","String"],"description":"User-defined function resources\nused in the query. May be either a code resource to load from a\nGoogle Cloud Storage URI (<code>gs://bucket/path</code>), or an inline resource\nthat contains code for a user-defined function (UDF). Providing an\ninline code resource is equivalent to providing a URI for a file\ncontaining the same code. See <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/user-defined-functions\">User-Defined\nFunctions</a>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/queryjob\">Google::Cloud::Bigquery::QueryJob</a>"],"description":"A new query job object."}]},{"id":"query-instance","type":"instance","name":"query","title":["Google","Cloud","Bigquery","Dataset#query"],"description":"<p>Queries data and waits for the results. In this method, a <a data-custom-type=\"google/cloud/bigquery/queryjob\">QueryJob</a>\nis created and its results are saved to a temporary table, then read\nfrom the table. Timeouts and transient errors are generally handled\nas needed to complete the query.</p>\n\n<p>Sets the current dataset as the default dataset in the query. Useful\nfor using unqualified table names.</p>\n\n<p>When using standard SQL and passing arguments using <code>params</code>, Ruby\ntypes are mapped to BigQuery types as follows:</p>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th>BigQuery</th>\n      <th>Ruby</th>\n      <th>Notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><code>BOOL</code></td>\n      <td><code>true</code>/<code>false</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>INT64</code></td>\n      <td><code>Integer</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>FLOAT64</code></td>\n      <td><code>Float</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>STRING</code></td>\n      <td><code>STRING</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>DATETIME</code></td>\n      <td><code>DateTime</code></td>\n      <td><code>DATETIME</code> does not support time zone.</td>\n    </tr>\n    <tr>\n      <td><code>DATE</code></td>\n      <td><code>Date</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>TIMESTAMP</code></td>\n      <td><code>Time</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>TIME</code></td>\n      <td><code>Google::Cloud::BigQuery::Time</code></td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>BYTES</code></td>\n      <td><code>File</code>, <code>IO</code>, <code>StringIO</code>, or similar</td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td><code>ARRAY</code></td>\n      <td><code>Array</code></td>\n      <td>Nested arrays, <code>nil</code> values are not supported.</td>\n    </tr>\n    <tr>\n      <td><code>STRUCT</code></td>\n      <td><code>Hash</code></td>\n      <td>Hash keys may be strings or symbols.</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types\">Data Types</a>\nfor an overview of each BigQuery data type, including allowed values.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1063","resources":[{"title":"Querying Data","link":"https://cloud.google.com/bigquery/querying-data"}],"examples":[{"caption":"<p>Query using standard SQL:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ndata = dataset.query \"SELECT name FROM my_table\"\n\ndata.each do |row|\n  puts row[:name]\nend"},{"caption":"<p>Query using legacy SQL:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ndata = dataset.query \"SELECT name FROM my_table\",\n                     legacy_sql: true\n\ndata.each do |row|\n  puts row[:name]\nend"},{"caption":"<p>Query using positional query parameters:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ndata = dataset.query \"SELECT name FROM my_table WHERE id = ?\",\n                     params: [1]\n\ndata.each do |row|\n  puts row[:name]\nend"},{"caption":"<p>Query using named query parameters:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ndata = dataset.query \"SELECT name FROM my_table WHERE id = @id\",\n                     params: { id: 1 }\n\ndata.each do |row|\n  puts row[:name]\nend"},{"caption":"<p>Query using external data source:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = dataset.external csv_url do |csv|\n  csv.autodetect = true\n  csv.skip_leading_rows = 1\nend\n\ndata = dataset.query \"SELECT * FROM my_ext_table\",\n                     external: { my_ext_table: csv_table }\n\ndata.each do |row|\n  puts row[:name]\nend"}],"params":[{"name":"query","types":["String"],"description":"A query string, following the BigQuery <a href=\"https://cloud.google.com/bigquery/query-reference\">query\nsyntax</a>, of the\nquery to execute. Example: “SELECT count(f1) FROM\n[myProjectId:myDatasetId.myTableId]”.","optional":false,"nullable":false},{"name":"params","types":["Array","Hash"],"description":"Standard SQL only. Used to pass query\narguments when the <code>query</code> string contains either positional (<code>?</code>)\nor named (<code>@myparam</code>) query parameters. If value passed is an array\n<code>[\"foo\"]</code>, the query must use positional query parameters. If value\npassed is a hash <code>{ myparam: \"foo\" }</code>, the query must use named\nquery parameters. When set, <code>legacy_sql</code> will automatically be set\nto false and <code>standard_sql</code> to true.","optional":true,"default":"nil","nullable":true},{"name":"external","types":["Hash<String|Symbol, External::DataSource>"],"description":"A Hash\nthat represents the mapping of the external tables to the table\nnames used in the SQL query. The hash keys are the table names, and\nthe hash values are the external table objects. See <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"query-instance\">Dataset#query</a>.","optional":true,"default":"nil","nullable":true},{"name":"max","types":["Integer"],"description":"The maximum number of rows of data to return per\npage of results. Setting this flag to a small value such as 1000 and\nthen paging through results might improve reliability when the query\nresult set is large. In addition to this limit, responses are also\nlimited to 10 MB. By default, there is no maximum row count, and\nonly the byte limit applies.","optional":true,"default":"nil","nullable":true},{"name":"cache","types":["Boolean"],"description":"Whether to look for the result in the query\ncache. The query cache is a best-effort cache that will be flushed\nwhenever tables in the query are modified. The default value is\ntrue. For more information, see <a href=\"https://developers.google.com/bigquery/querying-data\">query\ncaching</a>.","optional":true,"default":"true","nullable":false},{"name":"standard_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\ndialect for this query. If set to true, the query will use standard\nSQL rather than the <a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect. When set to true, the values of <code>large_results</code> and\n<code>flatten</code> are ignored; the query will be run as if <code>large_results</code>\nis true and <code>flatten</code> is false. Optional. The default value is\ntrue.","optional":true,"default":"nil","nullable":true},{"name":"legacy_sql","types":["Boolean"],"description":"Specifies whether to use BigQuery’s\n<a href=\"https://cloud.google.com/bigquery/docs/reference/legacy-sql\">legacy\nSQL</a>\ndialect for this query. If set to false, the query will use\nBigQuery’s <a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/\">standard\nSQL</a>\nWhen set to false, the values of <code>large_results</code> and <code>flatten</code> are\nignored; the query will be run as if <code>large_results</code> is true and\n<code>flatten</code> is false. Optional. The default value is false.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/data\">Google::Cloud::Bigquery::Data</a>"],"description":"A new data object."}]},{"id":"external-instance","type":"instance","name":"external","title":["Google","Cloud","Bigquery","Dataset#external"],"description":"<p>Creates a new External::DataSource (or subclass) object that\nrepresents the external data source that can be queried from directly,\neven though the data is not stored in BigQuery. Instead of loading or\nstreaming the data, this object references the external data source.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1132","resources":[{"title":"Querying\nExternal Data Sources","link":"https://cloud.google.com/bigquery/external-data-sources"}],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\"\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = dataset.external csv_url do |csv|\n  csv.autodetect = true\n  csv.skip_leading_rows = 1\nend\n\ndata = dataset.query \"SELECT * FROM my_ext_table\",\n                      external: { my_ext_table: csv_table }\n\ndata.each do |row|\n  puts row[:name]\nend"}],"params":[{"name":"url","types":["String","Array<String>"],"description":"The fully-qualified URL(s) that\npoint to your data in Google Cloud. An attempt will be made to\nderive the format from the URLs provided.","optional":false,"nullable":false},{"name":"format","types":["String|Symbol"],"description":"The data format. This value will be used\neven if the provided URLs are recognized as a different format.\nOptional.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n  <li><code>sheets</code> - Google Sheets</li>\n  <li><code>datastore_backup</code> - Cloud Datastore backup</li>\n  <li><code>bigtable</code> - Bigtable</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"yield","types":["block"],"description":"","optional":true,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/external/datasource\">External::DataSource</a>"],"description":"External data source."}]},{"id":"load_job-instance","type":"instance","name":"load_job","title":["Google","Cloud","Bigquery","Dataset#load_job"],"description":"<p>Loads data into the provided destination table using an asynchronous\nmethod. In this method, a <a data-custom-type=\"google/cloud/bigquery/loadjob\">LoadJob</a> is immediately returned. The\ncaller may poll the service by repeatedly calling <a data-custom-type=\"google/cloud/bigquery/job\" data-method=\"reload!-instance\">Job#reload!</a> and\n<a data-custom-type=\"google/cloud/bigquery/job\" data-method=\"done?-instance\">Job#done?</a> to detect when the job is done, or simply block until the\njob is done by calling #<a data-custom-type=\"google/cloud/bigquery/job\" data-method=\"wait_until_done!-instance\">Job#wait_until_done!</a>. See also <a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"load-instance\">#load</a>.</p>\n\n<p>For the source of the data, you can pass a google-cloud storage file\npath or a google-cloud-storage <code>File</code> instance. Or, you can upload a\nfile directly. See <a href=\"https://cloud.google.com/bigquery/loading-data-post-request#multipart\">Loading Data with a POST\nRequest</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1342","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ngs_url = \"gs://my-bucket/file-name.csv\"\nload_job = dataset.load_job \"my_new_table\", gs_url do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend"},{"caption":"<p>Pass a google-cloud-storage <code>File</code> instance:</p>","code":"require \"google/cloud/bigquery\"\nrequire \"google/cloud/storage\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nstorage = Google::Cloud::Storage.new\nbucket = storage.bucket \"my-bucket\"\nfile = bucket.file \"file-name.csv\"\nload_job = dataset.load_job \"my_new_table\", file do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend"},{"caption":"<p>Upload a file directly:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nfile = File.open \"my_data.csv\"\nload_job = dataset.load_job \"my_new_table\", file do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend"},{"caption":"<p>Schema is not required with a Cloud Datastore backup:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nload_job = dataset.load_job \"my_new_table\",\n                        \"gs://my-bucket/xxxx.kind_name.backup_info\",\n                        format: \"datastore_backup\""}],"params":[{"name":"table_id","types":["String"],"description":"The destination table to load the data into.","optional":false,"nullable":false},{"name":"file","types":["File","Google::Cloud::Storage::File","String","URI"],"description":"A file\nor the URI of a Google Cloud Storage file containing data to load\ninto the table.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is\n<code>csv</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n  <li><code>datastore_backup</code> - Cloud Datastore backup</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables. The default value is <code>needed</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in\nthe table. The default value is <code>append</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - An error will be returned if the table already contains\ndata.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"projection_fields","types":["Array<String>"],"description":"If the <code>format</code> option is set\nto <code>datastore_backup</code>, indicates which entity properties to load\nfrom a Cloud Datastore backup. Property names are case sensitive and\nmust be top-level properties. If not set, BigQuery loads all\nproperties. If any named property isn’t found in the Cloud Datastore\nbackup, an invalid error is returned.","optional":true,"default":"nil","nullable":true},{"name":"jagged_rows","types":["Boolean"],"description":"Accept rows that are missing trailing\noptional columns. The missing values are treated as nulls. If\n<code>false</code>, records with missing trailing columns are treated as bad\nrecords, and if there are too many bad records, an invalid error is\nreturned in the job result. The default value is <code>false</code>. Only\napplicable to CSV, ignored for other formats.","optional":true,"default":"nil","nullable":true},{"name":"quoted_newlines","types":["Boolean"],"description":"Indicates if BigQuery should allow\nquoted data sections that contain newline characters in a CSV file.\nThe default value is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"autodetect","types":["Boolean"],"description":"Indicates if BigQuery should\nautomatically infer the options and schema for CSV and JSON sources.\nThe default value is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"encoding","types":["String"],"description":"The character encoding of the data. The\nsupported values are <code>UTF-8</code> or <code>ISO-8859-1</code>. The default value is\n<code>UTF-8</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Specifices the separator for fields in a CSV\nfile. BigQuery converts the string to <code>ISO-8859-1</code> encoding, and\nthen uses the first byte of the encoded string to split the data in\nits raw, binary state. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Indicates if BigQuery should allow\nextra values that are not represented in the table schema. If true,\nthe extra values are ignored. If false, records with extra columns\nare treated as bad records, and if there are too many bad records,\nan invalid error is returned in the job result. The default value is\n<code>false</code>.</p>\n\n<p>The <code>format</code> property determines what BigQuery treats as an extra\nvalue:</p>\n\n<ul>\n  <li><code>CSV</code>: Trailing columns</li>\n  <li><code>JSON</code>: Named values that don’t match any column names</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"max_bad_records","types":["Integer"],"description":"The maximum number of bad records\nthat BigQuery can ignore when running the job. If the number of bad\nrecords exceeds this value, an invalid error is returned in the job\nresult. The default value is <code>0</code>, which requires that all records\nare valid.","optional":true,"default":"nil","nullable":true},{"name":"null_marker","types":["String"],"description":"Specifies a string that represents a null\nvalue in a CSV file. For example, if you specify <code>\\N</code>, BigQuery\ninterprets <code>\\N</code> as a null value when loading a CSV file. The default\nvalue is the empty string. If you set this property to a custom\nvalue, BigQuery throws an error if an empty string is present for\nall data types except for STRING and BYTE. For STRING and BYTE\ncolumns, BigQuery interprets the empty string as an empty value.","optional":true,"default":"nil","nullable":true},{"name":"quote","types":["String"],"description":"The value that is used to quote data sections in\na CSV file. BigQuery converts the string to ISO-8859-1 encoding, and\nthen uses the first byte of the encoded string to split the data in\nits raw, binary state. The default value is a double-quote\n<code>\"</code>. If your data does not contain quoted sections, set\nthe property value to an empty string. If your data contains quoted\nnewline characters, you must also set the allowQuotedNewlines\nproperty to true.","optional":true,"default":"nil","nullable":true},{"name":"skip_leading","types":["Integer"],"description":"The number of rows at the top of a CSV\nfile that BigQuery will skip when loading the data. The default\nvalue is <code>0</code>. This property is useful if you have header rows in the\nfile that should be skipped.","optional":true,"default":"nil","nullable":true},{"name":"schema","types":["Google::Cloud::Bigquery::Schema"],"description":"The schema for the\ndestination table. Optional. The schema can be omitted if the\ndestination table already exists, or if you’re loading data from a\nGoogle Cloud Datastore backup.</p>\n\n<p>See <a data-custom-type=\"google/cloud/bigquery/project\" data-method=\"schema-instance\">Project#schema</a> for the creation of the schema for use with\nthis option. Also note that for most use cases, the block yielded by\nthis method is a more convenient way to configure the schema.","optional":true,"default":"nil","nullable":true},{"name":"job_id","types":["String"],"description":"A user-defined ID for the load job. The ID\nmust contain only letters (a-z, A-Z), numbers (0-9), underscores\n(_), or dashes (-). The maximum length is 1,024 characters. If\n<code>job_id</code> is provided, then <code>prefix</code> will not be used.</p>\n\n<p>See <a href=\"https://cloud.google.com/bigquery/docs/managing-jobs#generate-jobid\">Generating a job\nID</a>.","optional":true,"default":"nil","nullable":true},{"name":"prefix","types":["String"],"description":"A string, usually human-readable, that will be\nprepended to a generated value to produce a unique job ID. For\nexample, the prefix <code>daily_import_job_</code> can be given to generate a\njob ID such as <code>daily_import_job_12vEDtMQ0mbp1Mo5Z7mzAFQJZazh</code>. The\nprefix must contain only letters (a-z, A-Z), numbers (0-9),\nunderscores (_), or dashes (-). The maximum length of the entire ID\nis 1,024 characters. If <code>job_id</code> is provided, then <code>prefix</code> will not\nbe used.","optional":true,"default":"nil","nullable":true},{"name":"labels","types":["Hash"],"description":"A hash of user-provided labels associated with\nthe job. You can use these to organize and group your jobs. Label\nkeys and values can be no longer than 63 characters, can only\ncontain lowercase letters, numeric characters, underscores and\ndashes. International characters are allowed. Label values are\noptional. Label keys must start with a letter and each label in the\nlist must have a different key.","optional":true,"default":"nil","nullable":true},{"name":"yield","types":["block"],"description":"A block for setting the schema for the destination\ntable. The schema can be omitted if the destination table already\nexists, or if you’re loading data from a Google Cloud Datastore\nbackup.","optional":true,"nullable":false},{"name":"yield.schema","types":["Google::Cloud::Bigquery::Schema"],"description":"The schema\ninstance provided using the <code>schema</code> option, or a new, empty schema\ninstance","optional":false,"nullable":false}],"exceptions":[{"type":"Google::Cloud::Error","description":""}],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/loadjob\">Google::Cloud::Bigquery::LoadJob</a>"],"description":"A new load job object."}]},{"id":"load-instance","type":"instance","name":"load","title":["Google","Cloud","Bigquery","Dataset#load"],"description":"<p>Loads data into the provided destination table using a synchronous\nmethod that blocks for a response. Timeouts and transient errors are\ngenerally handled as needed to complete the job. See also\n<a data-custom-type=\"google/cloud/bigquery/dataset\" data-method=\"load_job-instance\">#load_job</a>.</p>\n\n<p>For the source of the data, you can pass a google-cloud storage file\npath or a google-cloud-storage <code>File</code> instance. Or, you can upload a\nfile directly. See <a href=\"https://cloud.google.com/bigquery/loading-data-post-request#multipart\">Loading Data with a POST\nRequest</a>.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1552","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ngs_url = \"gs://my-bucket/file-name.csv\"\ndataset.load \"my_new_table\", gs_url do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend"},{"caption":"<p>Pass a google-cloud-storage <code>File</code> instance:</p>","code":"require \"google/cloud/bigquery\"\nrequire \"google/cloud/storage\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nstorage = Google::Cloud::Storage.new\nbucket = storage.bucket \"my-bucket\"\nfile = bucket.file \"file-name.csv\"\ndataset.load \"my_new_table\", file do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend"},{"caption":"<p>Upload a file directly:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nfile = File.open \"my_data.csv\"\ndataset.load \"my_new_table\", file do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend"},{"caption":"<p>Schema is not required with a Cloud Datastore backup:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\ndataset.load \"my_new_table\",\n             \"gs://my-bucket/xxxx.kind_name.backup_info\",\n             format: \"datastore_backup\""}],"params":[{"name":"table_id","types":["String"],"description":"The destination table to load the data into.","optional":false,"nullable":false},{"name":"file","types":["File","Google::Cloud::Storage::File","String","URI"],"description":"A file\nor the URI of a Google Cloud Storage file containing data to load\ninto the table.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is\n<code>csv</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n  <li><code>datastore_backup</code> - Cloud Datastore backup</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables. The default value is <code>needed</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in\nthe table. The default value is <code>append</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - An error will be returned if the table already contains\ndata.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"projection_fields","types":["Array<String>"],"description":"If the <code>format</code> option is set\nto <code>datastore_backup</code>, indicates which entity properties to load\nfrom a Cloud Datastore backup. Property names are case sensitive and\nmust be top-level properties. If not set, BigQuery loads all\nproperties. If any named property isn’t found in the Cloud Datastore\nbackup, an invalid error is returned.","optional":true,"default":"nil","nullable":true},{"name":"jagged_rows","types":["Boolean"],"description":"Accept rows that are missing trailing\noptional columns. The missing values are treated as nulls. If\n<code>false</code>, records with missing trailing columns are treated as bad\nrecords, and if there are too many bad records, an invalid error is\nreturned in the job result. The default value is <code>false</code>. Only\napplicable to CSV, ignored for other formats.","optional":true,"default":"nil","nullable":true},{"name":"quoted_newlines","types":["Boolean"],"description":"Indicates if BigQuery should allow\nquoted data sections that contain newline characters in a CSV file.\nThe default value is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"autodetect","types":["Boolean"],"description":"Indicates if BigQuery should\nautomatically infer the options and schema for CSV and JSON sources.\nThe default value is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"encoding","types":["String"],"description":"The character encoding of the data. The\nsupported values are <code>UTF-8</code> or <code>ISO-8859-1</code>. The default value is\n<code>UTF-8</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Specifices the separator for fields in a CSV\nfile. BigQuery converts the string to <code>ISO-8859-1</code> encoding, and\nthen uses the first byte of the encoded string to split the data in\nits raw, binary state. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Indicates if BigQuery should allow\nextra values that are not represented in the table schema. If true,\nthe extra values are ignored. If false, records with extra columns\nare treated as bad records, and if there are too many bad records,\nan invalid error is returned in the job result. The default value is\n<code>false</code>.</p>\n\n<p>The <code>format</code> property determines what BigQuery treats as an extra\nvalue:</p>\n\n<ul>\n  <li><code>CSV</code>: Trailing columns</li>\n  <li><code>JSON</code>: Named values that don’t match any column names</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"max_bad_records","types":["Integer"],"description":"The maximum number of bad records\nthat BigQuery can ignore when running the job. If the number of bad\nrecords exceeds this value, an invalid error is returned in the job\nresult. The default value is <code>0</code>, which requires that all records\nare valid.","optional":true,"default":"nil","nullable":true},{"name":"null_marker","types":["String"],"description":"Specifies a string that represents a null\nvalue in a CSV file. For example, if you specify <code>\\N</code>, BigQuery\ninterprets <code>\\N</code> as a null value when loading a CSV file. The default\nvalue is the empty string. If you set this property to a custom\nvalue, BigQuery throws an error if an empty string is present for\nall data types except for STRING and BYTE. For STRING and BYTE\ncolumns, BigQuery interprets the empty string as an empty value.","optional":true,"default":"nil","nullable":true},{"name":"quote","types":["String"],"description":"The value that is used to quote data sections in\na CSV file. BigQuery converts the string to ISO-8859-1 encoding, and\nthen uses the first byte of the encoded string to split the data in\nits raw, binary state. The default value is a double-quote\n<code>\"</code>. If your data does not contain quoted sections, set\nthe property value to an empty string. If your data contains quoted\nnewline characters, you must also set the allowQuotedNewlines\nproperty to true.","optional":true,"default":"nil","nullable":true},{"name":"skip_leading","types":["Integer"],"description":"The number of rows at the top of a CSV\nfile that BigQuery will skip when loading the data. The default\nvalue is <code>0</code>. This property is useful if you have header rows in the\nfile that should be skipped.","optional":true,"default":"nil","nullable":true},{"name":"schema","types":["Google::Cloud::Bigquery::Schema"],"description":"The schema for the\ndestination table. Optional. The schema can be omitted if the\ndestination table already exists, or if you’re loading data from a\nGoogle Cloud Datastore backup.</p>\n\n<p>See <a data-custom-type=\"google/cloud/bigquery/project\" data-method=\"schema-instance\">Project#schema</a> for the creation of the schema for use with\nthis option. Also note that for most use cases, the block yielded by\nthis method is a more convenient way to configure the schema.","optional":true,"default":"nil","nullable":true},{"name":"yield","types":["block"],"description":"A block for setting the schema for the destination\ntable. The schema can be omitted if the destination table already\nexists, or if you’re loading data from a Google Cloud Datastore\nbackup.","optional":true,"nullable":false},{"name":"yield.schema","types":["Google::Cloud::Bigquery::Schema"],"description":"The schema\ninstance provided using the <code>schema</code> option, or a new, empty schema\ninstance","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["Boolean"],"description":"Returns <code>true</code> if the load job was successful."}]},{"id":"reload!-instance","type":"instance","name":"reload!","title":["Google","Cloud","Bigquery","Dataset#reload!"],"description":"<p>Reloads the dataset with current data from the BigQuery service.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1599","resources":[],"examples":[{"caption":"<p>Skip retrieving the dataset from the service, then load it:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\", skip_lookup: true\ndataset.reload!"}],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/dataset\">Google::Cloud::Bigquery::Dataset</a>"],"description":"Returns the reloaded\ndataset."}]},{"id":"exists?-instance","type":"instance","name":"exists?","title":["Google","Cloud","Bigquery","Dataset#exists?"],"description":"<p>Determines whether the dataset exists in the BigQuery service. The\nresult is cached locally.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1623","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\", skip_lookup: true\ndataset.exists? # true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"<code>true</code> when the dataset exists in the BigQuery\nservice, <code>false</code> otherwise."}]},{"id":"reference?-instance","type":"instance","name":"reference?","title":["Google","Cloud","Bigquery","Dataset#reference?"],"description":"<p>Whether the dataset was created without retrieving the resource\nrepresentation from the BigQuery service.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1652","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\", skip_lookup: true\n\ndataset.reference? # true\ndataset.reload!\ndataset.reference? # false"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"<code>true</code> when the dataset is just a local reference\nobject, <code>false</code> otherwise."}]},{"id":"resource?-instance","type":"instance","name":"resource?","title":["Google","Cloud","Bigquery","Dataset#resource?"],"description":"<p>Whether the dataset was created with a resource representation from\nthe BigQuery service.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1674","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\", skip_lookup: true\n\ndataset.resource? # false\ndataset.reload!\ndataset.resource? # true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"<code>true</code> when the dataset was created with a resource\nrepresentation, <code>false</code> otherwise."}]},{"id":"resource_partial?-instance","type":"instance","name":"resource_partial?","title":["Google","Cloud","Bigquery","Dataset#resource_partial?"],"description":"<p>Whether the dataset was created with a partial resource representation\nfrom the BigQuery service by retrieval through <a data-custom-type=\"google/cloud/bigquery/project\" data-method=\"datasets-instance\">Project#datasets</a>.\nSee <a href=\"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/list#response\">Datasets: list\nresponse</a>\nfor the contents of the partial representation. Accessing any\nattribute outside of the partial representation will result in loading\nthe full representation.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1701","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.datasets.first\n\ndataset.resource_partial? # true\ndataset.description # Loads the full resource.\ndataset.resource_partial? # false"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"<code>true</code> when the dataset was created with a partial\nresource representation, <code>false</code> otherwise."}]},{"id":"resource_full?-instance","type":"instance","name":"resource_full?","title":["Google","Cloud","Bigquery","Dataset#resource_full?"],"description":"<p>Whether the dataset was created with a full resource representation\nfrom the BigQuery service.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1721","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\"\n\ndataset.resource_full? # true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"<code>true</code> when the dataset was created with a full\nresource representation, <code>false</code> otherwise."}]},{"id":"insert-instance","type":"instance","name":"insert","title":["Google","Cloud","Bigquery","Dataset#insert"],"description":"<p>Inserts data into the given table for near-immediate querying, without\nthe need to complete a load operation before the data can appear in\nquery results.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1814","resources":[{"title":"Streaming Data Into BigQuery","link":"https://cloud.google.com/bigquery/streaming-data-into-bigquery"}],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nrows = [\n  { \"first_name\" => \"Alice\", \"age\" => 21 },\n  { \"first_name\" => \"Bob\", \"age\" => 22 }\n]\ndataset.insert \"my_table\", rows"},{"caption":"<p>Avoid retrieving the dataset with <code>skip_lookup</code>:</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ndataset = bigquery.dataset \"my_dataset\", skip_lookup: true\n\nrows = [\n  { \"first_name\" => \"Alice\", \"age\" => 21 },\n  { \"first_name\" => \"Bob\", \"age\" => 22 }\n]\ndataset.insert \"my_table\", rows"},{"caption":"<p>Using <code>autocreate</code> to create a new table if none exists.</p>","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\n\nrows = [\n  { \"first_name\" => \"Alice\", \"age\" => 21 },\n  { \"first_name\" => \"Bob\", \"age\" => 22 }\n]\ndataset.insert \"my_table\", rows, autocreate: true do |t|\n  t.schema.string \"first_name\", mode: :required\n  t.schema.integer \"age\", mode: :required\nend"}],"params":[{"name":"table_id","types":["String"],"description":"The ID of the destination table.","optional":false,"nullable":false},{"name":"rows","types":["Hash","Array<Hash>"],"description":"A hash object or array of hash objects\ncontaining the data. Required.","optional":false,"nullable":false},{"name":"skip_invalid","types":["Boolean"],"description":"Insert all valid rows of a request, even\nif invalid rows exist. The default value is <code>false</code>, which causes\nthe entire request to fail if any invalid rows exist.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Accept rows that contain values that\ndo not match the schema. The unknown values are ignored. Default is\nfalse, which treats unknown values as errors.","optional":true,"default":"nil","nullable":true},{"name":"autocreate","types":["Boolean"],"description":"Specifies whether the method should create\na new table with the given <code>table_id</code>, if no table is found for\n<code>table_id</code>. The default value is false.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/insertresponse\">Google::Cloud::Bigquery::InsertResponse</a>"],"description":"An insert response\nobject."}]},{"id":"insert_async-instance","type":"instance","name":"insert_async","title":["Google","Cloud","Bigquery","Dataset#insert_async"],"description":"<p>Create an asynchronous inserter object used to insert rows in batches.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/dataset.rb#L1889","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\ndataset = bigquery.dataset \"my_dataset\"\ninserter = dataset.insert_async \"my_table\" do |result|\n  if result.error?\n    log_error result.error\n  else\n    log_insert \"inserted #{result.insert_count} rows \" \\\n      \"with #{result.error_count} errors\"\n  end\nend\n\nrows = [\n  { \"first_name\" => \"Alice\", \"age\" => 21 },\n  { \"first_name\" => \"Bob\", \"age\" => 22 }\n]\ninserter.insert rows\n\ninserter.stop.wait!"}],"params":[{"name":"table_id","types":["String"],"description":"The ID of the table to insert rows into.","optional":false,"nullable":false},{"name":"skip_invalid","types":["Boolean"],"description":"Insert all valid rows of a request, even\nif invalid rows exist. The default value is <code>false</code>, which causes\nthe entire request to fail if any invalid rows exist.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Accept rows that contain values that\ndo not match the schema. The unknown values are ignored. Default is\nfalse, which treats unknown values as errors.","optional":true,"default":"nil","nullable":true},{"name":"max_rows","types":["Integer"],"description":"The maximum number of rows to be collected\nbefore the batch is published. Default is 500.","optional":true,"default":"500","nullable":false},{"name":"yield","types":["block"],"description":"the callback for when a batch of rows is inserted","optional":true,"nullable":false},{"name":"yield.result","types":["Table::AsyncInserter::Result"],"description":"the result of the\nasynchronous insert","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/bigquery/table/asyncinserter\">Table::AsyncInserter</a>"],"description":"Returns an inserter object."}]}]}