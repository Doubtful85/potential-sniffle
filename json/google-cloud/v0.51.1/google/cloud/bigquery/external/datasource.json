{"id":"google/cloud/bigquery/external/datasource","name":"DataSource","title":["Google","Cloud","Bigquery","External","DataSource"],"description":"<h1 id=\"datasource\">DataSource</h1>\n\n<p>External::DataSource and its subclasses represents an external data\nsource that can be queried from directly, even though the data is not\nstored in BigQuery. Instead of loading or streaming the data, this\nobject references the external data source.</p>\n\n<p>The AVRO and Datastore Backup formats use <a data-custom-type=\"google/cloud/bigquery/external/datasource\">External::DataSource</a>. See\n<a data-custom-type=\"google/cloud/bigquery/external/csvsource\">External::CsvSource</a>, <a data-custom-type=\"google/cloud/bigquery/external/jsonsource\">External::JsonSource</a>,\n<a data-custom-type=\"google/cloud/bigquery/external/sheetssource\">External::SheetsSource</a>, <a data-custom-type=\"google/cloud/bigquery/external/bigtablesource\">External::BigtableSource</a> for the other\nformats.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L153","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\navro_url = \"gs://bucket/path/to/data.avro\"\navro_table = bigquery.external avro_url do |avro|\n  avro.autodetect = true\nend\n\ndata = bigquery.query \"SELECT * FROM my_ext_table\",\n                      external: { my_ext_table: avro_table }\n\ndata.each do |row|\n  puts row[:name]\nend"}],"methods":[{"id":"format-instance","type":"instance","name":"format","title":["Google","Cloud","Bigquery","External","DataSource#format"],"description":"<p>The data format. For CSV files, specify “CSV”. For Google sheets,\nspecify “GOOGLE_SHEETS”. For newline-delimited JSON, specify\n“NEWLINE_DELIMITED_JSON”. For Avro files, specify “AVRO”. For Google\nCloud Datastore backups, specify “DATASTORE_BACKUP”. [Beta] For\nGoogle Cloud Bigtable, specify “BIGTABLE”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L183","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url\n\ncsv_table.format #=> \"CSV\""}],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":""}]},{"id":"csv?-instance","type":"instance","name":"csv?","title":["Google","Cloud","Bigquery","External","DataSource#csv?"],"description":"<p>Whether the data format is “CSV”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L203","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url\n\ncsv_table.format #=> \"CSV\"\ncsv_table.csv? #=> true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"json?-instance","type":"instance","name":"json?","title":["Google","Cloud","Bigquery","External","DataSource#json?"],"description":"<p>Whether the data format is “NEWLINE_DELIMITED_JSON”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L223","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\njson_url = \"gs://bucket/path/to/data.json\"\njson_table = bigquery.external json_url\n\njson_table.format #=> \"NEWLINE_DELIMITED_JSON\"\njson_table.json? #=> true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"sheets?-instance","type":"instance","name":"sheets?","title":["Google","Cloud","Bigquery","External","DataSource#sheets?"],"description":"<p>Whether the data format is “GOOGLE_SHEETS”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L243","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nsheets_url = \"https://docs.google.com/spreadsheets/d/1234567980\"\nsheets_table = bigquery.external sheets_url\n\nsheets_table.format #=> \"GOOGLE_SHEETS\"\nsheets_table.sheets? #=> true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"avro?-instance","type":"instance","name":"avro?","title":["Google","Cloud","Bigquery","External","DataSource#avro?"],"description":"<p>Whether the data format is “AVRO”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L263","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\navro_url = \"gs://bucket/path/to/data.avro\"\navro_table = bigquery.external avro_url\n\navro_table.format #=> \"AVRO\"\navro_table.avro? #=> true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"backup?-instance","type":"instance","name":"backup?","title":["Google","Cloud","Bigquery","External","DataSource#backup?"],"description":"<p>Whether the data format is “DATASTORE_BACKUP”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L283","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nbackup_url = \"gs://bucket/path/to/data.backup_info\"\nbackup_table = bigquery.external backup_url\n\nbackup_table.format #=> \"DATASTORE_BACKUP\"\nbackup_table.backup? #=> true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"bigtable?-instance","type":"instance","name":"bigtable?","title":["Google","Cloud","Bigquery","External","DataSource#bigtable?"],"description":"<p>Whether the data format is “BIGTABLE”.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L303","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\nbigtable_url = \"https://googleapis.com/bigtable/projects/...\"\nbigtable_table = bigquery.external bigtable_url\n\nbigtable_table.format #=> \"BIGTABLE\"\nbigtable_table.bigtable? #=> true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"urls-instance","type":"instance","name":"urls","title":["Google","Cloud","Bigquery","External","DataSource#urls"],"description":"<p>The fully-qualified URIs that point to your data in Google Cloud.\nFor Google Cloud Storage URIs: Each URI can contain one ‘<em>’ wildcard\ncharacter and it must come after the ‘bucket’ name. Size limits\nrelated to load jobs apply to external data sources. For Google\nCloud Bigtable URIs: Exactly one URI can be specified and it has be\na fully specified and valid HTTPS URL for a Google Cloud Bigtable\ntable. For Google Cloud Datastore backups, exactly one URI can be\nspecified, and it must end with ‘.backup_info’. Also, the ‘</em>’\nwildcard character is not allowed.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L330","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url\n\ncsv_table.urls #=> [\"gs://bucket/path/to/data.csv\"]"}],"params":[],"exceptions":[],"returns":[{"types":["Array&lt;String&gt;"],"description":""}]},{"id":"autodetect-instance","type":"instance","name":"autodetect","title":["Google","Cloud","Bigquery","External","DataSource#autodetect"],"description":"<p>Indicates if the schema and format options are detected\nautomatically.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L352","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.autodetect = true\nend\n\ncsv_table.autodetect #=> true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"autodetect=-instance","type":"instance","name":"autodetect=","title":["Google","Cloud","Bigquery","External","DataSource#autodetect="],"description":"<p>Set whether to detect schema and format options automatically. Any\noption specified explicitly will be honored.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L374","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.autodetect = true\nend\n\ncsv_table.autodetect #=> true"}],"params":[{"name":"new_autodetect","types":["Boolean"],"description":"New autodetect value","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"compression-instance","type":"instance","name":"compression","title":["Google","Cloud","Bigquery","External","DataSource#compression"],"description":"<p>The compression type of the data source. Possible values include\n<code>\"GZIP\"</code> and <code>nil</code>. The default value is <code>nil</code>. This setting is\nignored for Google Cloud Bigtable, Google Cloud Datastore backups\nand Avro formats. Optional.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L398","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.compression = \"GZIP\"\nend\n\ncsv_table.compression #=> \"GZIP\""}],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":""}]},{"id":"compression=-instance","type":"instance","name":"compression=","title":["Google","Cloud","Bigquery","External","DataSource#compression="],"description":"<p>Set the compression type of the data source. Possible values include\n<code>\"GZIP\"</code> and <code>nil</code>. The default value is <code>nil</code>. This setting is\nignored for Google Cloud Bigtable, Google Cloud Datastore backups\nand Avro formats. Optional.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L422","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.compression = \"GZIP\"\nend\n\ncsv_table.compression #=> \"GZIP\""}],"params":[{"name":"new_compression","types":["String"],"description":"New compression value","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"ignore_unknown-instance","type":"instance","name":"ignore_unknown","title":["Google","Cloud","Bigquery","External","DataSource#ignore_unknown"],"description":"<p>Indicates if BigQuery should allow extra values that are not\nrepresented in the table schema. If <code>true</code>, the extra values are\nignored. If <code>false</code>, records with extra columns are treated as bad\nrecords, and if there are too many bad records, an invalid error is\nreturned in the job result. The default value is <code>false</code>.</p>\n\n<p>BigQuery treats trailing columns as an extra in <code>CSV</code>, named values\nthat don’t match any column names in <code>JSON</code>. This setting is ignored\nfor Google Cloud Bigtable, Google Cloud Datastore backups and Avro\nformats. Optional.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L453","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.ignore_unknown = true\nend\n\ncsv_table.ignore_unknown #=> true"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"ignore_unknown=-instance","type":"instance","name":"ignore_unknown=","title":["Google","Cloud","Bigquery","External","DataSource#ignore_unknown="],"description":"<p>Set whether BigQuery should allow extra values that are not\nrepresented in the table schema. If <code>true</code>, the extra values are\nignored. If <code>false</code>, records with extra columns are treated as bad\nrecords, and if there are too many bad records, an invalid error is\nreturned in the job result. The default value is <code>false</code>.</p>\n\n<p>BigQuery treats trailing columns as an extra in <code>CSV</code>, named values\nthat don’t match any column names in <code>JSON</code>. This setting is ignored\nfor Google Cloud Bigtable, Google Cloud Datastore backups and Avro\nformats. Optional.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L483","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.ignore_unknown = true\nend\n\ncsv_table.ignore_unknown #=> true"}],"params":[{"name":"new_ignore_unknown","types":["Boolean"],"description":"New ignore_unknown value","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"max_bad_records-instance","type":"instance","name":"max_bad_records","title":["Google","Cloud","Bigquery","External","DataSource#max_bad_records"],"description":"<p>The maximum number of bad records that BigQuery can ignore when\nreading data. If the number of bad records exceeds this value, an\ninvalid error is returned in the job result. The default value is 0,\nwhich requires that all records are valid. This setting is ignored\nfor Google Cloud Bigtable, Google Cloud Datastore backups and Avro\nformats.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L510","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.max_bad_records = 10\nend\n\ncsv_table.max_bad_records #=> 10"}],"params":[],"exceptions":[],"returns":[{"types":["Integer"],"description":""}]},{"id":"max_bad_records=-instance","type":"instance","name":"max_bad_records=","title":["Google","Cloud","Bigquery","External","DataSource#max_bad_records="],"description":"<p>Set the maximum number of bad records that BigQuery can ignore when\nreading data. If the number of bad records exceeds this value, an\ninvalid error is returned in the job result. The default value is 0,\nwhich requires that all records are valid. This setting is ignored\nfor Google Cloud Bigtable, Google Cloud Datastore backups and Avro\nformats.</p>","source":"google-cloud-bigquery/lib/google/cloud/bigquery/external.rb#L536","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/bigquery\"\n\nbigquery = Google::Cloud::Bigquery.new\n\ncsv_url = \"gs://bucket/path/to/data.csv\"\ncsv_table = bigquery.external csv_url do |csv|\n  csv.max_bad_records = 10\nend\n\ncsv_table.max_bad_records #=> 10"}],"params":[{"name":"new_max_bad_records","types":["Integer"],"description":"New max_bad_records value","optional":false,"nullable":false}],"exceptions":[],"returns":[]}]}