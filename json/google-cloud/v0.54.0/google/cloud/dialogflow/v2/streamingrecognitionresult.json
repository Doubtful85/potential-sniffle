{"id":"google/cloud/dialogflow/v2/streamingrecognitionresult","name":"StreamingRecognitionResult","title":["Google","Cloud","Dialogflow","V2","StreamingRecognitionResult"],"description":"<p>Contains a speech recognition result corresponding to a portion of the audio\nthat is currently being processed or an indication that this is the end\nof the single requested utterance.</p>\n\n<p>Example:</p>\n\n<ol>\n  <li>\n    <p>transcript: “tube”</p>\n  </li>\n  <li>\n    <p>transcript: “to be a”</p>\n  </li>\n  <li>\n    <p>transcript: “to be”</p>\n  </li>\n  <li>\n    <p>transcript: “to be or not to be”\nis_final: true</p>\n  </li>\n  <li>\n    <p>transcript: “ that’s”</p>\n  </li>\n  <li>\n    <p>transcript: “ that is”</p>\n  </li>\n  <li>\n    <p>recognition_event_type: +RECOGNITION_EVENT_END_OF_SINGLE_UTTERANCE+</p>\n  </li>\n  <li>\n    <p>transcript: “ that is the question”\nis_final: true</p>\n  </li>\n</ol>\n\n<p>Only two of the responses contain final results (#4 and #8 indicated by\n+is_final: true+). Concatenating these generates the full transcript: “to be\nor not to be that is the question”.</p>\n\n<p>In each response we populate:</p>\n\n<ul>\n  <li>\n    <p>for +MESSAGE_TYPE_TRANSCRIPT+: +transcript+ and possibly +is_final+.</p>\n  </li>\n  <li>\n    <p>for +MESSAGE_TYPE_END_OF_SINGLE_UTTERANCE+: only +event_type+.</p>\n  </li>\n</ul>","source":"google-cloud-dialogflow/lib/google/cloud/dialogflow/v2/doc/google/cloud/dialogflow/v2/session.rb#L326","resources":[],"examples":[],"methods":[{"id":"message_type-instance","type":"instance","name":"message_type","title":["Google","Cloud","Dialogflow","V2","StreamingRecognitionResult#message_type"],"description":"","source":"google-cloud-dialogflow/lib/google/cloud/dialogflow/v2/doc/google/cloud/dialogflow/v2/session.rb#L326","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/dialogflow/v2/streamingrecognitionresult/messagetype\">Google::Cloud::Dialogflow::V2::StreamingRecognitionResult::MessageType</a>"],"description":"Type of the result message."}]},{"id":"message_type=-instance","type":"instance","name":"message_type=","title":["Google","Cloud","Dialogflow","V2","StreamingRecognitionResult#message_type="],"description":"","source":"google-cloud-dialogflow/lib/google/cloud/dialogflow/v2/doc/google/cloud/dialogflow/v2/session.rb#L326","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/dialogflow/v2/streamingrecognitionresult/messagetype\">Google::Cloud::Dialogflow::V2::StreamingRecognitionResult::MessageType</a>"],"description":"Type of the result message."}]},{"id":"transcript-instance","type":"instance","name":"transcript","title":["Google","Cloud","Dialogflow","V2","StreamingRecognitionResult#transcript"],"description":"","source":"google-cloud-dialogflow/lib/google/cloud/dialogflow/v2/doc/google/cloud/dialogflow/v2/session.rb#L326","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"Transcript text representing the words that the user spoke.\nPopulated if and only if +event_type+ = +RECOGNITION_EVENT_TRANSCRIPT+."}]},{"id":"transcript=-instance","type":"instance","name":"transcript=","title":["Google","Cloud","Dialogflow","V2","StreamingRecognitionResult#transcript="],"description":"","source":"google-cloud-dialogflow/lib/google/cloud/dialogflow/v2/doc/google/cloud/dialogflow/v2/session.rb#L326","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["String"],"description":"Transcript text representing the words that the user spoke.\nPopulated if and only if +event_type+ = +RECOGNITION_EVENT_TRANSCRIPT+."}]},{"id":"is_final-instance","type":"instance","name":"is_final","title":["Google","Cloud","Dialogflow","V2","StreamingRecognitionResult#is_final"],"description":"","source":"google-cloud-dialogflow/lib/google/cloud/dialogflow/v2/doc/google/cloud/dialogflow/v2/session.rb#L326","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["true","false"],"description":"The default of 0.0 is a sentinel value indicating +confidence+ was not set.\nIf +false+, the +StreamingRecognitionResult+ represents an\ninterim result that may change. If +true+, the recognizer will not return\nany further hypotheses about this piece of the audio. May only be populated\nfor +event_type+ = +RECOGNITION_EVENT_TRANSCRIPT+."}]},{"id":"is_final=-instance","type":"instance","name":"is_final=","title":["Google","Cloud","Dialogflow","V2","StreamingRecognitionResult#is_final="],"description":"","source":"google-cloud-dialogflow/lib/google/cloud/dialogflow/v2/doc/google/cloud/dialogflow/v2/session.rb#L326","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["true","false"],"description":"The default of 0.0 is a sentinel value indicating +confidence+ was not set.\nIf +false+, the +StreamingRecognitionResult+ represents an\ninterim result that may change. If +true+, the recognizer will not return\nany further hypotheses about this piece of the audio. May only be populated\nfor +event_type+ = +RECOGNITION_EVENT_TRANSCRIPT+."}]},{"id":"confidence-instance","type":"instance","name":"confidence","title":["Google","Cloud","Dialogflow","V2","StreamingRecognitionResult#confidence"],"description":"","source":"google-cloud-dialogflow/lib/google/cloud/dialogflow/v2/doc/google/cloud/dialogflow/v2/session.rb#L326","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Float"],"description":"The Speech confidence between 0.0 and 1.0 for the current portion of audio.\nA higher number indicates an estimated greater likelihood that the\nrecognized words are correct. The default of 0.0 is a sentinel value\nindicating that confidence was not set.</p>\n\n<p>This field is typically only provided if +is_final+ is true and you should\nnot rely on it being accurate or even set."}]},{"id":"confidence=-instance","type":"instance","name":"confidence=","title":["Google","Cloud","Dialogflow","V2","StreamingRecognitionResult#confidence="],"description":"","source":"google-cloud-dialogflow/lib/google/cloud/dialogflow/v2/doc/google/cloud/dialogflow/v2/session.rb#L326","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Float"],"description":"The Speech confidence between 0.0 and 1.0 for the current portion of audio.\nA higher number indicates an estimated greater likelihood that the\nrecognized words are correct. The default of 0.0 is a sentinel value\nindicating that confidence was not set.</p>\n\n<p>This field is typically only provided if +is_final+ is true and you should\nnot rely on it being accurate or even set."}]}]}